{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indo BERT Fine-Tuning News Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c276c188f5140148441ca79f2cfb162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f1c3f0a37e942bebdaca25140d372d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c3438c7dde747c690c5fabfe9ac7ce8",
              "IPY_MODEL_84b64f8cadca434c89e6bad7d14af924"
            ]
          }
        },
        "9f1c3f0a37e942bebdaca25140d372d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c3438c7dde747c690c5fabfe9ac7ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08368eac78a54e8093e5566e6fb63e33",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64ef13ab60fe4bac9e575cbf4965a6fe"
          }
        },
        "84b64f8cadca434c89e6bad7d14af924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd851ba950cb4d3b94d52a8f169354a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 3.57MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34dfadfd0bfa4a00ad3e4630181abf1e"
          }
        },
        "08368eac78a54e8093e5566e6fb63e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64ef13ab60fe4bac9e575cbf4965a6fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd851ba950cb4d3b94d52a8f169354a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34dfadfd0bfa4a00ad3e4630181abf1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16f29f699fb549b684b1d5b24d69277e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ef17ceb7a11498baac99c81d69f5178",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84858824df1b4ee3a5f878730eb06928",
              "IPY_MODEL_987bb53ce8a44b5ca53efdf1ee731cd3"
            ]
          }
        },
        "5ef17ceb7a11498baac99c81d69f5178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84858824df1b4ee3a5f878730eb06928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_923fe38881f74f269efccc6a8392444a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08a7b2eb5e4a4bd2be5010491a55551a"
          }
        },
        "987bb53ce8a44b5ca53efdf1ee731cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21e2227dd76441d6b529591c8a6d7044",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 832B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c46a54d5a524d48869d638adaf9b705"
          }
        },
        "923fe38881f74f269efccc6a8392444a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08a7b2eb5e4a4bd2be5010491a55551a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21e2227dd76441d6b529591c8a6d7044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c46a54d5a524d48869d638adaf9b705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "593b45739c5b42a89e285ece483c7661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1527de23da9b46b88a7ea1ca932095fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f294ac1c793646a1a063df0758c27e5f",
              "IPY_MODEL_c92089740dca45eb9ffabc190bee95ff"
            ]
          }
        },
        "1527de23da9b46b88a7ea1ca932095fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f294ac1c793646a1a063df0758c27e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c53eb4959174d76a9b71f646a44e769",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ed86384a5874183a36167483d48cdda"
          }
        },
        "c92089740dca45eb9ffabc190bee95ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_816914c3c4c942da9608d39b325575be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [01:13&lt;00:00, 9.65MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abd72196a0a74d68a6ed43ac9e77a17a"
          }
        },
        "1c53eb4959174d76a9b71f646a44e769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ed86384a5874183a36167483d48cdda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "816914c3c4c942da9608d39b325575be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abd72196a0a74d68a6ed43ac9e77a17a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDlE5n-Jap0M",
        "colab_type": "code",
        "outputId": "031c41e5-5fa7-4673-8518-cecb2b1a8e46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil --q\n",
        "!pip install psutil --q\n",
        "!pip install humanize --q\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 26.4 GB  | Proc size: 159.3 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KinixNmEA1Mi",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH15tJAM8tc0",
        "colab_type": "code",
        "outputId": "54a402fd-ad9b-4ba6-aae9-acf4b4a7c47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        "\n",
        "ROOT = \"/content/drive/\"     # default location for the drive\n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0WYXOnZ7s3-",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Using Colab GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncHH9X9H2oqV",
        "colab_type": "code",
        "outputId": "653a8c28-7165-412d-fd98-84be1379fd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJYNoCEi7xMQ",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Install Hugging Face library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua52hPaj7LPF",
        "colab_type": "code",
        "outputId": "5c2d9fd3-8bbe-4555-8f13-5fec8ca4d460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install transformers --q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 3.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 15.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 23.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 30.4MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBsQyFBq71zE",
        "colab_type": "text"
      },
      "source": [
        "# 2. Load Indonesian News Dataset\n",
        "\n",
        "Topic : bola, news, bisnis, tekno, otomotif"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaud1cmrZE6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dict mapping\n",
        "label2num = {'bola':0, 'news':1, 'bisnis':2, 'tekno':3, 'otomotif':4}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaRbE4cxOO9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "data_path = 'drive/My Drive/DSI/data/'\n",
        "train_path = data_path+'training.res'\n",
        "test_path = data_path+'testing.res'\n",
        "\n",
        "train = pickle.load(open(train_path, 'rb'))\n",
        "test = pickle.load(open(test_path, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpUaRCrN7jaz",
        "colab_type": "code",
        "outputId": "40231678-54a6-461f-c64b-b44c571ebd68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.DataFrame({'text': train[0], 'label': train[1]})\n",
        "test = pd.DataFrame({'text': test[0], 'label': test[1]})\n",
        "\n",
        "print('Number of training sentences: {:,}\\n'.format(train.shape[0]))\n",
        "print('Number of testing sentences: {:,}\\n'.format(test.shape[0]))\n",
        "\n",
        "# Display 5 random rows from the data.\n",
        "train.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 6,127\n",
            "\n",
            "Number of testing sentences: 2,627\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1061</th>\n",
              "      <td>Liputan6.com, Turin - Sassuolo tak berdaya men...</td>\n",
              "      <td>bola</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>Liputan6.com, Jakarta - Penyidik Polres Metro ...</td>\n",
              "      <td>news</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Liputan6.com, Jakarta Timnas Indonesia U-22 ba...</td>\n",
              "      <td>bola</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163</th>\n",
              "      <td>Liputan6.com, Chicago - Harga emas turun pada ...</td>\n",
              "      <td>bisnis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5875</th>\n",
              "      <td>Liputan6.com, London - Partai perdelapan final...</td>\n",
              "      <td>bola</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text   label\n",
              "1061  Liputan6.com, Turin - Sassuolo tak berdaya men...    bola\n",
              "1657  Liputan6.com, Jakarta - Penyidik Polres Metro ...    news\n",
              "99    Liputan6.com, Jakarta Timnas Indonesia U-22 ba...    bola\n",
              "1163  Liputan6.com, Chicago - Harga emas turun pada ...  bisnis\n",
              "5875  Liputan6.com, London - Partai perdelapan final...    bola"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4sE06hzZqJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode label\n",
        "train.label = train.label.map(label2num)\n",
        "test.label = test.label.map(label2num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO8fM7qfRBh8",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR0EFgoHRFwH",
        "colab_type": "code",
        "outputId": "e6edbb09-b2b8-41f9-ed2e-104ac594cab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import collections\n",
        "nltk.download('punkt')\n",
        "\n",
        "def get_frequent_word(df):\n",
        "    text = \" \".join(list(df['text'].str.lower()))\n",
        "    word_list = word_tokenize(text)\n",
        "    word_count = dict(collections.Counter(word_list))\n",
        "    d_word_freq = pd.DataFrame(data = {'word': list(word_count.keys()), 'freq': list(word_count.values())})\n",
        "    \n",
        "    return d_word_freq\n",
        "\n",
        "def cleansing(text, stopword = None):\n",
        "    word_list = word_tokenize(text.lower())\n",
        "    word_list = [word for word in word_list if len(word) > 2]\n",
        "    word_list = [word for word in word_list if word.isalnum()]\n",
        "    if stopword == None:\n",
        "        text = ' '.join(word_list)\n",
        "    else:\n",
        "        word_list = [word for word in word_list if word not in stopword]\n",
        "        text = ' '.join(word_list)\n",
        "                \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1LOsLD1RV6J",
        "colab_type": "code",
        "outputId": "8329c038-dbed-475f-d29e-a48fb00c7105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# Get frekuensi kemunculan kata\n",
        "d_w_f = get_frequent_word(train)\n",
        "# Check alphanumeric\n",
        "d_w_f['is_alnum'] = d_w_f.word.str.isalnum()\n",
        "# select only alphanumeric word (ignore punctuation)\n",
        "d_w_f_selected = d_w_f[d_w_f['is_alnum'] == True].sort_values(by = 'freq', ascending = False)\n",
        "print(d_w_f_selected.head(15))\n",
        "print(d_w_f_selected.tail(15))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          word   freq  is_alnum\n",
            "60        yang  22988      True\n",
            "43          di  22859      True\n",
            "96         dan  18465      True\n",
            "21         ini  12634      True\n",
            "109     dengan  10181      True\n",
            "72       untuk  10092      True\n",
            "29        dari   8955      True\n",
            "134        itu   8409      True\n",
            "35        pada   7787      True\n",
            "83     jakarta   7029      True\n",
            "79        akan   6789      True\n",
            "203      dalam   6527      True\n",
            "76       tidak   5392      True\n",
            "33        juga   4838      True\n",
            "236  indonesia   4691      True\n",
            "              word  freq  is_alnum\n",
            "27517      cimarga     1      True\n",
            "27518     menganga     1      True\n",
            "27520        sardi     1      True\n",
            "27524  diposanjoyo     1      True\n",
            "27525       mangun     1      True\n",
            "27526        jak59     1      True\n",
            "27539          uki     1      True\n",
            "27541        penas     1      True\n",
            "27560      bromley     1      True\n",
            "27561       ngebut     1      True\n",
            "27564      palermo     1      True\n",
            "27565         naum     1      True\n",
            "27570    seketaris     1      True\n",
            "27571     perngkat     1      True\n",
            "44411        quang     1      True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtUn_USwSsM3",
        "colab_type": "code",
        "outputId": "af4a4b4d-137d-41bb-be17-fa84b5a16757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create stopwords list\n",
        "stopwords = list(d_w_f_selected[(d_w_f_selected['freq'] > 5000) | (d_w_f_selected['freq'] < 2)].word)\n",
        "print(stopwords[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yang', 'di', 'dan', 'ini', 'dengan', 'untuk', 'dari', 'itu', 'pada', 'jakarta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGET9t_S-Kf",
        "colab_type": "code",
        "outputId": "aa8ab63f-86f8-43cc-d72b-1db103f2a149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i in tqdm(range(len(train))):\n",
        "    train.loc[i, 'text_cleansing'] = cleansing(train.loc[i, 'text'], stopword=stopwords)\n",
        "\n",
        "for i in tqdm(range(len(test))):\n",
        "    test.loc[i, 'text_cleansing'] = cleansing(test.loc[i, 'text'], stopword=stopwords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6127/6127 [04:36<00:00, 22.18it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2627/2627 [01:58<00:00, 22.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5VR8UGY-RWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training data only use 4000 sentences\n",
        "sentences = train.text_cleansing.values[:4000]\n",
        "labels = train.label.values[:4000]\n",
        "\n",
        "# Testing data only use 1000 sentence\n",
        "test_sentences = test.text_cleansing.values[:1000]\n",
        "test_labels = test.label.values[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mr3OGkU_dio",
        "colab_type": "text"
      },
      "source": [
        "# 3. Tokenization & Input Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrFVXHiL_plT",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9prBry5a_Wnl",
        "colab_type": "code",
        "outputId": "ac1930de-d518-4f2c-f239-aa7fc2d9970c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "4c276c188f5140148441ca79f2cfb162",
            "9f1c3f0a37e942bebdaca25140d372d1",
            "9c3438c7dde747c690c5fabfe9ac7ce8",
            "84b64f8cadca434c89e6bad7d14af924",
            "08368eac78a54e8093e5566e6fb63e33",
            "64ef13ab60fe4bac9e575cbf4965a6fe",
            "bd851ba950cb4d3b94d52a8f169354a6",
            "34dfadfd0bfa4a00ad3e4630181abf1e"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c276c188f5140148441ca79f2cfb162",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v88GigAAYKO",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Required Formatting\n",
        "\n",
        "We are required to:\n",
        "\n",
        "1.   Tambah special tokens di awal dan akhir setiap kalimat\n",
        "2.   Pad or truncate semua kalimat ke length tertentu\n",
        "3.   Prepare \"attention mask\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLZYRPsUBYbh",
        "colab_type": "text"
      },
      "source": [
        "### Special Tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohyDCP-uBe65",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**`[SEP]`**\n",
        "\n",
        "Pada akhir setiap kalimat, kita perlu menambahkan `[SEP]` token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG9_XcP_GUNs",
        "colab_type": "text"
      },
      "source": [
        "**`[CLS]`**\n",
        "\n",
        "Untuk classification tasks, kita harus menambahkan `[CLS]` token ke setiap awal kalimat.\n",
        "\n",
        "![Illustration of CLS token purpose](http://www.mccormickml.com/assets/BERT/CLS_token_500x606.png)\n",
        "\n",
        "On the output of the final (12th) transformer, *only the first embedding (corresponding to the [CLS] token) is used by the classifier*.\n",
        "\n",
        ">  \"The first token of every sequence is always a special classification token (`[CLS]`). The final hidden state\n",
        "corresponding to this token is used as the aggregate sequence representation for classification\n",
        "tasks.\" (from the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCHjvATFGZRx",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Length & Attention Mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYqIX2K_G1Ig",
        "colab_type": "text"
      },
      "source": [
        "Panjang kalimat dalam dataset sangat bervariasi, jadi gimana cara-nya BERT handle ini ?\n",
        "\n",
        "BERT punya 2 batasan :\n",
        "1. Semua kalimat harus di pad atau truncate menjadi satu fixed length\n",
        "2. Max sentence length is 512 tokens\n",
        "\n",
        "Padding menggunakan special token `[PAD]`\n",
        "\n",
        "<img src=\"http://www.mccormickml.com/assets/BERT/padding_and_mask.png\" width=\"600\">\n",
        "\n",
        "\"Attention Mask\" adalah array yang terdiri dari '1' dan '0' dimana '1' mengindikasikan token tsb adalah padding dan '0' yang bukan. Mask ini memberitahu  pada \"Self-Attention\" pada BERT untuk tidak memasukkan token `[PAD]` ini saat menginterpretasikan kalimat\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98eLfUw4G6aB",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Tokenize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSfnMPoQAMvG",
        "colab_type": "code",
        "outputId": "d7deaddb-2ff9-433f-d2d6-3c7c84dbe668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import statistics\n",
        "sent_length = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    sent_length.append(len(input_ids))\n",
        "\n",
        "print('Average length = ', sum(sent_length)/len(sent_length))\n",
        "print('Median length = ', statistics.median(sent_length))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (869 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (750 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (648 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (674 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (874 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (780 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1023 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (937 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (885 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (672 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1139 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (859 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (651 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (749 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (822 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average length =  232.984\n",
            "Median length =  218.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np2aBSm5HXdK",
        "colab_type": "text"
      },
      "source": [
        "Max length di set menjadi 256."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WKqKbytHcqB",
        "colab_type": "text"
      },
      "source": [
        "Fungsi `tokenizer.encode_plus` melakukan beberapa langkah :\n",
        "\n",
        "1. Split kalimat jadi token.\n",
        "2. Tambah special token (`[CLS]` and `[SEP]`)\n",
        "3. Mapping token menjadi ID\n",
        "4. Pad atau truncate semua kalimat menjadi same length.\n",
        "5. Buat attention mask\n",
        "\n",
        "Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghIRKJzPHL9C",
        "colab_type": "code",
        "outputId": "813b20b7-b0b0-4d2d-92d8-fb45172a8655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  london lee dixon khawatir arsenal tak bisa merekrut denis suarez secara permanen musim panas nanti pasalnya sejauh suarez hanya menjadi cadangan bagi the gunners suarez dipinjam arsenal barcelona januari lalu the gunners juga bisa membelinya akhir musim nanti jika permainannya memuaskan namun sejauh suarez tak menjadi pilihan utama arsenal manajer unai emery baru memberinya kesempatan bermain selama menit emery mungkin tahu kualitas suarez dia tahu suarez pemain kata dixon seperti dilansir evening standard namun sudut pandang suarez dia pasti berpikir apa pindah kalau bermain jadi mungkin saja dia menolak arsenal katanya menambahkan\n",
            "Token IDs: tensor([   101,  10406,  10605,  10115,  10141,  10112, 105154,  10115,    179,\n",
            "        101917,  13259,  10129,  10456,  62191,  10161,  12741,  17103,  22336,\n",
            "         63051,  11159,  10140,  10291,  10603,  34305,  14635,  10178,  38154,\n",
            "         10115,  25386,  53215,  10799,  10325,  26088,  27302,  10113,  27271,\n",
            "         18593,  10603,  34305,  18029,  11999,  11782,  15728,  15941,  10105,\n",
            "         23103,  34663,  10603,  34305,  10120,  17298,  36887,  10456,  62191,\n",
            "         10161,  18121,  32942,  12920,  10910,  31288,  10105,  23103,  34663,\n",
            "         11535,  17103,  10911,  97465,  10676,  26814,  25386,  10799,  10325,\n",
            "         37873,  48163,  10676,  10911,  78314,  41864,  22736,  27271,  18593,\n",
            "         10603,  34305,  12741,  11999,  60717,  19307,  10456,  62191,  10161,\n",
            "         18970,  17792,  10153,  10116,  10266,  23131,  18049,  45112,  10676,\n",
            "         21388,  82188,  26246,  21041,  90256,  10266,  23131,  33125,  81565,\n",
            "         15694,  13133,  11390,  10603,  34305,  10671,  81565,  10603,  34305,\n",
            "         23609,  21907, 105154,  10115,  13908,  36031,  15008,  10835,  42135,\n",
            "         14979,  22736,  11660,  11159,  24960,  24058,  10603,  34305,  10671,\n",
            "         91688,  10347,  33394,  20897,  10129,  32500,  72895,  84844,  10138,\n",
            "         26246,  17760,  33125,  44725,  10671,  79964,  10456,  62191,  10161,\n",
            "         21907,  10676,  54779,  96272,    102,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnXshwAuIWJg",
        "colab_type": "text"
      },
      "source": [
        "## 3.4. Training & Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek2FQzD0Hwdc",
        "colab_type": "code",
        "outputId": "907668ac-5b3a-4aab-86fe-26db137b329b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 80-20 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3,200 training samples\n",
            "  800 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CqLcDEUIxpy",
        "colab_type": "text"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwgORTDPItW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgSbgr3pPSmq",
        "colab_type": "text"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_N0umjEPac8",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWwozSM5Pt6O",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA3x1UxuPO_2",
        "colab_type": "code",
        "outputId": "f15b92c7-2a2a-43e7-965b-dfd9470fc90b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "16f29f699fb549b684b1d5b24d69277e",
            "5ef17ceb7a11498baac99c81d69f5178",
            "84858824df1b4ee3a5f878730eb06928",
            "987bb53ce8a44b5ca53efdf1ee731cd3",
            "923fe38881f74f269efccc6a8392444a",
            "08a7b2eb5e4a4bd2be5010491a55551a",
            "21e2227dd76441d6b529591c8a6d7044",
            "7c46a54d5a524d48869d638adaf9b705",
            "593b45739c5b42a89e285ece483c7661",
            "1527de23da9b46b88a7ea1ca932095fa",
            "f294ac1c793646a1a063df0758c27e5f",
            "c92089740dca45eb9ffabc190bee95ff",
            "1c53eb4959174d76a9b71f646a44e769",
            "6ed86384a5874183a36167483d48cdda",
            "816914c3c4c942da9608d39b325575be",
            "abd72196a0a74d68a6ed43ac9e77a17a"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-multilingual-cased', # Use the 12-layer BERT model, with an cased vocab.\n",
        "    num_labels = 5, \n",
        "    output_attentions = False, # return attentions weights\n",
        "    output_hidden_states = False, # returns all hidden-states\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16f29f699fb549b684b1d5b24d69277e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "593b45739c5b42a89e285ece483c7661",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJxGFavTQuBB",
        "colab_type": "text"
      },
      "source": [
        "Show model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZCkTXj9QLCv",
        "colab_type": "code",
        "outputId": "02dbc3a2-2736-4dea-fd03-1dfa67ad7c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUd50eRRCDr",
        "colab_type": "text"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCBTpQpmRGnE",
        "colab_type": "text"
      },
      "source": [
        "Untuk fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 3\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWjSdRVVQ0p5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsu9PdP-RYeR",
        "colab_type": "code",
        "outputId": "260d9c44-9614-4b63-bb61-81736d26b586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "print('Jumlah batch :', len(train_dataloader))\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah batch : 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN8TArj3OK1E",
        "colab_type": "text"
      },
      "source": [
        "`get_linear_schedule_with_warmup` function :\n",
        "Create a schedule with a learning rate that decreases linearly after linearly increasing during a warmup period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKS78j5vRqaB",
        "colab_type": "text"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RcbEkN7Rw6d",
        "colab_type": "text"
      },
      "source": [
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data to GPU\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data to GPU\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9H5Gc9bSD9M",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsJsG7mVRdn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QJd7XJiSJRF",
        "colab_type": "text"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Egi63SNSFzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM8SCN5ISPfF",
        "colab_type": "text"
      },
      "source": [
        "Ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM2Hri3TSLy1",
        "colab_type": "code",
        "outputId": "96fb26c5-79a1-42de-d377-b1d444745e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# List variable for store training and validation loss, validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 20 batches.\n",
        "        if step % 20 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a backward pass\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # token_type_ids is same as the \"segment ids\", which differentiates \n",
        "        # sentence 1 and 2 in sentence-pair tasks\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None,\n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode (batchnorm, dropout disable)\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Deactivate autograd, it will reduce memory usage and speed up computations\n",
        "        # but you wonâ€™t be able to backprop (which you donâ€™t want in an eval script).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'Epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Validation Loss': avg_val_loss,\n",
        "            'Validation Accuracy': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch    20  of    100.    Elapsed: 0:00:16.\n",
            "  Batch    40  of    100.    Elapsed: 0:00:31.\n",
            "  Batch    60  of    100.    Elapsed: 0:00:46.\n",
            "  Batch    80  of    100.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epoch took: 0:01:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.36\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    20  of    100.    Elapsed: 0:00:15.\n",
            "  Batch    40  of    100.    Elapsed: 0:00:30.\n",
            "  Batch    60  of    100.    Elapsed: 0:00:46.\n",
            "  Batch    80  of    100.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epoch took: 0:01:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.30\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    20  of    100.    Elapsed: 0:00:15.\n",
            "  Batch    40  of    100.    Elapsed: 0:00:30.\n",
            "  Batch    60  of    100.    Elapsed: 0:00:46.\n",
            "  Batch    80  of    100.    Elapsed: 0:01:01.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epoch took: 0:01:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  Validation Loss: 0.28\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:04:06 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGFUatydT5SW",
        "colab_type": "text"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Db3I5BeSoMF",
        "colab_type": "code",
        "outputId": "940707ce-ac87-4f1b-b502-c99e9c0e2ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('Epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Validation Accuracy</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:01:17</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0:01:16</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0:01:16</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Validation Loss  ...  Training Time Validation Time\n",
              "Epoch                                  ...                               \n",
              "1               0.69             0.36  ...        0:01:17         0:00:06\n",
              "2               0.29             0.30  ...        0:01:16         0:00:06\n",
              "3               0.20             0.28  ...        0:01:16         0:00:06\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9QSXQ0dX0c5",
        "colab_type": "code",
        "outputId": "1d3c53b0-680d-4561-cf32-c914c803112d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Validation Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAGaCAYAAAC2bw3EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd1jT1/4H8HcCSdigCA5AxQEossRRK60KIqi4GY66ah2tq7a2am3vbXuv7b1q3dXWca1bmU7cq7W1Uhc4UFscFUVFlBEQkpD8/vBH2ggqYMI3wPv1PH2em5Pv9+SdyHnuJ9+c7zkijUajARERERERGR2x0AGIiIiIiKhsLNaJiIiIiIwUi3UiIiIiIiPFYp2IiIiIyEixWCciIiIiMlIs1omIiIiIjBSLdSKqsdLT0+Hu7o6lS5dWuo+ZM2fC3d1dj6lqrud93u7u7pg5c2a5+li6dCnc3d2Rnp6u93zx8fFwd3fHqVOn9N43EZGhmAodgIhqj4oUvYcPH4azs7MB01Q/BQUF+O6775CYmIgHDx6gbt268Pf3x3vvvYfmzZuXq48pU6Zg//792L59O1q1alXmMRqNBkFBQcjNzcWJEydgZmamz7dhUKdOnUJSUhJGjhwJGxsboeOUkp6ejqCgIAwbNgz/+Mc/hI5DRNUAi3UiqjJz587VeXzmzBls27YNUVFR8Pf313mubt26r/x6Tk5OSElJgYmJSaX7+Ne//oUvvvjilbPow6effoo9e/YgLCwMHTp0QGZmJo4cOYLk5ORyF+vh4eHYv38/4uLi8Omnn5Z5zK+//oo7d+4gKipKL4V6SkoKxOKq+SE3KSkJy5Ytw4ABA0oV6/369UPv3r0hkUiqJAsRkT6wWCeiKtOvXz+dx8XFxdi2bRt8fX1LPfcsuVwOKyurCr2eSCSCTCarcM6/M5bC7smTJ9i3bx8CAgLwzTffaNsnTZoEhUJR7n4CAgLQsGFD7Nq1Cx9//DGkUmmpY+Lj4wE8Lez14VX/DfTFxMTklb64EREJgXPWicjoBAYGYvjw4bh8+TLGjBkDf39/9O3bF8DTon3hwoWIiIhAx44d0aZNGwQHB2P+/Pl48uSJTj9lzaH+e9vRo0cxaNAgeHl5ISAgAP/973+hUql0+ihrznpJW15eHv75z3+iU6dO8PLywuDBg5GcnFzq/Tx+/BizZs1Cx44d4efnhxEjRuDy5csYPnw4AgMDy/WZiEQiiESiMr88lFVwP49YLMaAAQOQnZ2NI0eOlHpeLpfjwIEDcHNzg7e3d4U+7+cpa866Wq3G999/j8DAQHh5eSEsLAw7d+4s8/y0tDR8/vnn6N27N/z8/ODj44OBAwciJiZG57iZM2di2bJlAICgoCC4u7vr/Ps/b876o0eP8MUXX6BLly5o06YNunTpgi+++AKPHz/WOa7k/JMnT2LNmjXo3r072rRpg5CQECQkJJTrs6iIK1euYOLEiejYsSO8vLzQq1cvrFq1CsXFxTrHZWRkYNasWejWrRvatGmDTp06YfDgwTqZ1Go1fvjhB/Tp0wd+fn5o27YtQkJC8Mknn0CpVOo9OxHpD6+sE5FRunv3LkaOHInQ0FD06NEDBQUFAID79+8jNjYWPXr0QFhYGExNTZGUlITVq1cjNTUVa9asKVf/x48fx+bNmzF48GAMGjQIhw8fxv/+9z/Y2tpiwoQJ5epjzJgxqFu3LiZOnIjs7GysXbsW48aNw+HDh7W/AigUCowePRqpqakYOHAgvLy8cPXqVYwePRq2trbl/jzMzMzQv39/xMXFYffu3QgLCyv3uc8aOHAgVqxYgfj4eISGhuo8t2fPHhQWFmLQoEEA9Pd5P+vrr7/G+vXr0b59e4waNQpZWVn48ssv4eLiUurYpKQknD59Gl27doWzs7P2V4ZPP/0Ujx49wvjx4wEAUVFRkMvlOHjwIGbNmoU6deoAePG9Enl5eRgyZAhu3bqFQYMGoXXr1khNTcWWLVvw66+/IiYmptQvOgsXLkRhYSGioqIglUqxZcsWzJw5E40bNy41nauyLly4gOHDh8PU1BTDhg1DvXr1cPToUcyfPx9XrlzR/rqiUqkwevRo3L9/H0OHDkXTpk0hl8tx9epVnD59GgMGDAAArFixAkuWLEG3bt0wePBgmJiYID09HUeOHIFCoTCaX5CIqAwaIiKBxMXFadzc3DRxcXE67d26ddO4ublpoqOjS51TVFSkUSgUpdoXLlyocXNz0yQnJ2vbbt++rXFzc9MsWbKkVJuPj4/m9u3b2na1Wq3p3bu3pnPnzjr9zpgxQ+Pm5lZm2z//+U+d9sTERI2bm5tmy5Yt2raNGzdq3NzcNMuXL9c5tqS9W7dupd5LWfLy8jRjx47VtGnTRtO6dWvNnj17ynXe84wYMULTqlUrzf3793XaIyMjNZ6enpqsrCyNRvPqn7dGo9G4ublpZsyYoX2clpamcXd314wYMUKjUqm07RcvXtS4u7tr3NzcdP5t8vPzS71+cXGx5q233tK0bdtWJ9+SJUtKnV+i5O/t119/1bYtWLBA4+bmptm4caPOsSX/PgsXLix1fr9+/TRFRUXa9nv37mk8PT0106ZNK/Wazyr5jL744osXHhcVFaVp1aqVJjU1VdumVqs1U6ZM0bi5uWl++eUXjUaj0aSmpmrc3Nw0K1eufGF//fv31/Ts2fOl+YjI+HAaDBEZJTs7OwwcOLBUu1Qq1V4FVKlUyMnJwaNHj/D6668DQJnTUMoSFBSks9qMSCRCx44dkZmZifz8/HL1MWrUKJ3Hr732GgDg1q1b2rajR4/CxMQEI0aM0Dk2IiIC1tbW5XodtVqNqVOn4sqVK9i7dy/efPNNTJ8+Hbt27dI57rPPPoOnp2e55rCHh4ejuLgY27dv17alpaXh/PnzCAwM1N7gq6/P++8OHz4MjUaD0aNH68wh9/T0ROfOnUsdb2Fhof3fRUVFePz4MbKzs9G5c2fI5XJcv369whlKHDx4EHXr1kVUVJROe1RUFOrWrYtDhw6VOmfo0KE6U4/q168PV1dX3Lx5s9I5/i4rKwvnzp1DYGAgPDw8tO0ikQjvvvuuNjcA7d/QqVOnkJWV9dw+rayscP/+fZw+fVovGYmo6nAaDBEZJRcXl+feDLhp0yZs3boVf/zxB9Rqtc5zOTk55e7/WXZ2dgCA7OxsWFpaVriPkmkX2dnZ2rb09HQ4OjqW6k8qlcLZ2Rm5ubkvfZ3Dhw/jxIkTmDdvHpydnbF48WJMmjQJH3/8MVQqlXaqw9WrV+Hl5VWuOew9evSAjY0N4uPjMW7cOABAXFwcAGinwJTQx+f9d7dv3wYANGvWrNRzzZs3x4kTJ3Ta8vPzsWzZMuzduxcZGRmlzinPZ/g86enpaNOmDUxNdf/v0NTUFE2bNsXly5dLnfO8v507d+5UOsezmQCgRYsWpZ5r1qwZxGKx9jN0cnLChAkTsHLlSgQEBKBVq1Z47bXXEBoaCm9vb+15H3zwASZOnIhhw4bB0dERHTp0QNeuXRESElKhex6IqOqxWCcio2Rubl5m+9q1a/Gf//wHAQEBGDFiBBwdHSGRSHD//n3MnDkTGo2mXP2/aFWQV+2jvOeXV8kNke3btwfwtNBftmwZ3n33XcyaNQsqlQoeHh5ITk7GnDlzytWnTCZDWFgYNm/ejLNnz8LHxwc7d+5EgwYN8MYbb2iP09fn/So+/PBDHDt2DJGRkWjfvj3s7OxgYmKC48eP44cffij1BcLQqmoZyvKaNm0awsPDcezYMZw+fRqxsbFYs2YN3nnnHXz00UcAAD8/Pxw8eBAnTpzAqVOncOrUKezevRsrVqzA5s2btV9Uicj4sFgnomplx44dcHJywqpVq3SKph9//FHAVM/n5OSEkydPIj8/X+fqulKpRHp6erk27il5n3fu3EHDhg0BPC3Yly9fjgkTJuCzzz6Dk5MT3Nzc0L9//3JnCw8Px+bNmxEfH4+cnBxkZmZiwoQJOp+rIT7vkivT169fR+PGjXWeS0tL03mcm5uLY8eOoV+/fvjyyy91nvvll19K9S0SiSqc5caNG1CpVDpX11UqFW7evFnmVXRDK5me9ccff5R67vr161Cr1aVyubi4YPjw4Rg+fDiKioowZswYrF69Gm+//Tbs7e0BAJaWlggJCUFISAiAp7+YfPnll4iNjcU777xj4HdFRJVlXJcHiIheQiwWQyQS6VzRValUWLVqlYCpni8wMBDFxcVYv369Tnt0dDTy8vLK1UeXLl0APF2F5O/z0WUyGRYsWAAbGxukp6cjJCSk1HSOF/H09ESrVq2QmJiITZs2QSQSlVpb3RCfd2BgIEQiEdauXauzDOGlS5dKFeAlXxCevYL/4MGDUks3An/Nby/v9Jzu3bvj0aNHpfqKjo7Go0eP0L1793L1o0/29vbw8/PD0aNHce3aNW27RqPBypUrAQDBwcEAnq5m8+zSizKZTDvFqORzePToUanX8fT01DmGiIwTr6wTUbUSGhqKb775BmPHjkVwcDDkcjl2795doSK1KkVERGDr1q1YtGgR/vzzT+3Sjfv27UOTJk1Kretels6dOyM8PByxsbHo3bs3+vXrhwYNGuD27dvYsWMHgKeF17fffovmzZujZ8+e5c4XHh6Of/3rX/jpp5/QoUOHUldsDfF5N2/eHMOGDcPGjRsxcuRI9OjRA1lZWdi0aRM8PDx05olbWVmhc+fO2LlzJ8zMzODl5YU7d+5g27ZtcHZ21rk/AAB8fHwAAPPnz0efPn0gk8nQsmVLuLm5lZnlnXfewb59+/Dll1/i8uXLaNWqFVJTUxEbGwtXV1eDXXG+ePEili9fXqrd1NQU48aNw+zZszF8+HAMGzYMQ4cOhYODA44ePYoTJ04gLCwMnTp1AvB0itRnn32GHj16wNXVFZaWlrh48SJiY2Ph4+OjLdp79eoFX19feHt7w9HREZmZmYiOjoZEIkHv3r0N8h6JSD+M8//diIieY8yYMdBoNIiNjcWcOXPg4OCAnj17YtCgQejVq5fQ8UqRSqVYt24d5s6di8OHD2Pv3r3w9vbGDz/8gNmzZ6OwsLBc/cyZMwcdOnTA1q1bsWbNGiiVSjg5OSE0NBRvv/02pFIpoqKi8NFHH8Ha2hoBAQHl6rdPnz6YO3cuioqKSt1YChju8549ezbq1auH6OhozJ07F02bNsU//vEP3Lp1q9RNnfPmzcM333yDI0eOICEhAU2bNsW0adNgamqKWbNm6Rzr7++P6dOnY+vWrfjss8+gUqkwadKk5xbr1tbW2LJlC5YsWYIjR44gPj4e9vb2GDx4MCZPnlzhXXPLKzk5ucyVdKRSKcaNGwcvLy9s3boVS5YswZYtW1BQUAAXFxdMnz4db7/9tvZ4d3d3BAcHIykpCbt27YJarUbDhg0xfvx4nePefvttHD9+HBs2bEBeXh7s7e3h4+OD8ePH66w4Q0TGR6SpiruDiIhIR3FxMV577TV4e3tXemMhIiKq+ThnnYjIwMq6er5161bk5uaWua44ERFRCU6DISIysE8//RQKhQJ+fn6QSqU4d+4cdu/ejSZNmiAyMlLoeEREZMQ4DYaIyMC2b9+OTZs24ebNmygoKIC9vT26dOmCqVOnol69ekLHIyIiI8ZinYiIiIjISHHOOhERERGRkWKxTkRERERkpHiD6f97/DgfarV+ZwTZ21shK0uu1z6J6CmOLyLD4fgiMgyxWIQ6dSwrdA6L9f+nVmv0XqyX9EtEhsHxRWQ4HF9ExoHTYIiIiIiIjJSgV9YVCgUWL16MHTt2IDc3Fx4eHpg2bRo6der0wvMCAwNx586dMp9r0qQJDhw4YIi4RERERERVStBifebMmThw4ABGjBiBJk2aICEhAWPHjsWGDRvg5+f33PM++eQT5Ofn67TdvXsXixYt4m6ARERERFRjCFasp6SkYM+ePZg1axZGjRoFAOjfvz/CwsIwf/58bNq06bnndu/evVTb8uXLAQB9+vQxSF4iIiIioqom2Jz1ffv2QSKRICIiQtsmk8kQHh6OM2fO4MGDBxXqb/fu3XB2dkbbtm31HZWIiIiISBCCXVlPTU2Fq6srLC11l6/x9vaGRqNBamoqHB0dy9XX5cuXkZaWhgkTJhgiKhEREdViT57kQy7PQXGxUugoZKRMTCSwsrKFuXnFlmUsD8GK9czMTNSvX79Uu4ODAwBU6Mr6rl27AAB9+/bVTzgiIiIiAEqlAnl5j2FnVw8SiQwikUjoSGRkNBoNlMoiZGc/hKmpBBKJVK/9C1asFxYWQiKRlGqXyWQAgKKionL1o1arsWfPHrRu3RrNmzevdB57e6tKn/siDg7WBumXiDi+iAyJ4+upW7f+hI2NHSwsLISOQkZMIrGAWm0HpTIfjRrZ67VvwYp1MzMzKJWlf04qKdJLivaXSUpKwv3797U3qVZWVpZc7xtAODhYIzMzT699EtFTHF9EhsPx9Re5PB/29g2gUqmFjkJGTiIxQ1ZW9gvHjlgsqvAFYsGKdQcHhzKnumRmZgJAueer79q1C2KxGL1799Zrvldx8tI9xB9Pw6PcItS1kWFgl+bo5NlA6FhERERUQWp1McRiE6FjUDUgFptArS7Wf79677GcPDw8cOPGjVLrpScnJ2uffxmFQoEDBw6gQ4cOZc5/F8LJS/ewbu8VZOUWQQMgK7cI6/ZewclL94SORkRERJXAeepUHob6OxGsWA8NDYVSqURMTIy2TaFQID4+Hm3bttUW33fv3kVaWlqZfRw/fhy5ublGtbZ6/PE0KJ75qUyhUiP+eNnvgYiIiIjoeQSbBuPj44PQ0FDMnz8fmZmZaNy4MRISEnD37l18/fXX2uNmzJiBpKQkXL16tVQfu3btglQqRUhISFVGf6Gs3LJvjH1eOxEREVFNM2nSOADAsmUrq/TcmkiwYh0A5s6di0WLFmHHjh3IycmBu7s7Vq5cCX9//5eeK5fLcezYMXTt2hXW1sZzx7q9jazMwtzepnw3zBIREREZSkBAu3IdFxOzEw0bNjJwGioPkUaj0e8SKNWUvlaDKZmz/vepMCIAI3u6400fp1fun4ie4moVRIbD8fWXe/duoUGDJkLH0Jv9+xN1HkdHb8H9+xmYPPkDnfY33+wGc3PzSr9OyYp/ZS3Tbchzhfayv5dqtRpMTVWy6kvJajBW5hLkPVHizNWHeL1NQ5iaCHabABEREdVyISG9dB4fO3YYOTnZpdqfVVhYCDMzs3K/zqsU2tWxSDckFusG0MmzATp5NtBemTh+/g7W7buKdXuv4O3erXhXORERERmtSZPGQS6X4+OPP8HSpQtx9eoVDBs2AmPGjMdPPx3Dzp0JuHbtKnJzc+Dg4Ihevfpg+PDRMDEx0ekD+Gve+dmzpzFlygTMmTMXN25cx/btccjNzYGXlw8++ugTODu76OVcAIiLi8bWrZuQlfUQzZs3x6RJ07Bq1QqdPqsTFutVoIuvE3LkCmw/cQN21jIM6lL5nVaJiIioeivZjyUrtwj2RrofS3b2Y3z88TT06BGK0NDeqF//ab7ExN0wN7dAVNQwWFiY48yZ01i9+jvk5+dj4sSpL+133bo1EItNMHToCOTl5WLLlg344otPsWrVOr2cm5AQi4UL58LXty2iooYgIyMDs2ZNh7W1NRwcyreHj7FhsV5F+nRuisfyIuw5eQt2VjIE+TsLHYmIiIiq2LP3tpXsxwLAqAr2hw8zMXPmZwgL66fT/vnn/4ZM9td0mP79wzFv3ldISIjB2LHvQiqVvrBflUqF//1vHUxNn5agNja2WLx4Pq5f/wPNmrV4pXOVSiVWr14BT08vLFq0XHtcixYtMWfO5yzW6cVEIhHe6uGG3HwFNh+8BltLKdp5VM8/GiIiotrs5wsZOJGSUalz0+7mQFWsu6CFQqXG2sRU/Hj+boX6CvBuiM5eDSuV42XMzMwQGlp6d/i/F+oFBflQKJTw8fHDjh3xuHXrJlq2dHthv71799UW0QDg4+MLALh7985Li/WXnXvlymXk5OTgvfcG6BwXHByKJUsWvLBvY8ZivQqZiMUY39cT87eex8pdl2BtIYF74zpCxyIiIqIq8myh/rJ2oTg4OOoUvCWuX0/DqlUrcPbsb6V2oc/Pl7+035LpNCWsrW0AAHl5L1996GXn3rv39AvUs3PYTU1N0bChYb7UVAUW61VMKjHBlHBvfL3xDJbEXcCsYW3h7FixJXyIiIhIOJ29Kn9F+6PlPz93P5YZw9q+ajS9+fsV9BJ5eXmYPHkcLCysMGbMBDg5OUMqleLatStYsWIp1Gp1GT3pEotNymwvz0rir3JudcZ1BAVgZS7BB5G+kEnEWBB9Hlk5hUJHIiIioiowsEtzSE11yy+pqRgDq8HiE+fOnUFOTg5mz/4nIiOHoHPnN9C+fUftFW6hNWjw9AtUevptnXaVSoWMjMpNWzIGLNYFYm9rhg8ifVGkVGNB9HnInyiFjkREREQG1smzAUb29NDubG5vI8PInh5GdXPp84jFT8vGv1/JViqVSEiIESqSDg+P1rC1tcXOnQlQqVTa9oMH9yEvL1fAZK+G02AE5OxohSmDvPDNtvNYEpuC6YN9IZWU/RMPERER1Qwl+7FUN15e3rC2tsGcOZ8jPDwKIpEI+/cnwlhmoUgkErz99jgsXDgP77//Hrp1C0JGRgb27t0FJyfnarvPDa+sC8y9cR2M6+OJtDs5+H7nJRSXY74XERERUVWztbXD3LkLYW9fD6tWrcCWLRvRrl1HvPfeFKGjaQ0aFIX335+Oe/cy8O23i5GcfA7/+c8CWFlZQyqVCR2vUkSamj4rv5yysuRQq/X7UZTsYFoeh8+kY9PBa+ji2wgjQtyr7bc/oqpSkfFFRBXD8fWXe/duoUGDJkLHoFegVqsRFhaMLl26YcaMTw36Wi/7exGLRbC3r9jCIpwGYySC/J2R/f+bJtWxkqFvgKvQkYiIiIiqlaKiIshkulfQ9+3bg9zcHPj5+QuU6tWwWDciA99shuy8Imw/cQO2VlJ08XUSOhIRERFRtZGSch4rVixF166BsLGxxbVrV7Bnz040a9Yc3bp1FzpepbBYNyIikQgje3ogp0CB9fuvwsZSCr+WDkLHIiIiIqoWGjVyQr16DoiN3Ybc3BzY2NgiNLQ3JkyYBIlEInS8SuGc9f8n9Jz1vytUqDBvyzncyczH9CF+aOFkq9dcRDUB59QSGQ7H1184Z50qwhBz1rkajBEyk5piaoQP7KxlWByTjIys/JefREREREQ1Dot1I2VjIcUHUb4wEYuwYNt5PM4rvTUxEREREdVsLNaNmKOdOaZF+kJeqMLC6GQUFKpefhIRERER1Rgs1o1ckwbWmDTACxlZ+VgWnwKlipsmEREREdUWLNarAU/Xuni7dytc+TMbq3Zfhpr3BBMRERHVCizWq4lOng0Q2a0FTl95gK2HfgcX8SEiIiKq+bjOejUS2rExsuVFOPDbbdSxlqHna1xKioiIiKgm45X1aiYysAU6tHJEzLE0/HIxQ+g4REREVMslJu5CQEA7ZGTc1baFh/fBnDmfV+rcV3X27GkEBLTD2bOn9dankFisVzNikQhjerdGqyZ1sDbxCi5ezxI6EhEREVUjH388Dd27B+DJkyfPPeaDDyYhJKQLioqMd+noQ4f2Izp6s9AxDI7FejUkMRVj0kAvNKpniW8TLuJGRq7QkYiIiKiaCA4OQWFhIU6cOF7m848fP8KZM7/hzTe7QSaTVeo1Nm+Ow4wZn75KzJc6fPgAoqO3lGr39W2Lw4d/hq9vW4O+flVhsV5NmctMMS3SB9YWEiyKScb9xwVCRyIiIqJq4I03usLc3AKHDu0v8/kjRw6huLgYPXqEVvo1pFIpTE2FuTVSLBZDJpNBLK4ZZW7NeBe1lJ2VDB9E+UKjARZuS0ZOvkLoSERERGTkzMzM8MYbXZCU9Ctyc0v/On/o0H7Y29vDxaUJ5s//D4YMGYjAwM7o1SsIn346o1zzy8uas379ehqmTJmAwMDOGDCgF374YTXU6tL7x/z00zF89NFU9OsXim7dOiEysh9++GE1iouLtcdMmjQOP/10HPfuZSAgoB0CAtohPLwPgOfPWT98+ABGjx6KwMDXERYWjK+//hLZ2dk6x0yaNA6jRg3F9et/YNKkcQgK6oz+/Xti06Z1L33PhsLVYKq5BnUtMDXCG/O2nMOimGR8PMQP5jL+sxIRERmrpHtnsTNtHx4XZaOOzA59m4eiQ4OqnbIRHByKAwf24tixw+jbd4C2/d69DFy8mILw8MFITb2EixdT0L17CBwcHJGRcRfbt8dh8uTx2LgxBmZmZuV+vaysh5gyZQLUajXeemskzMzMsXNnQpnTbBITd8Pc3AJRUcNgYWGOM2dOY/Xq75Cfn4+JE6cCAEaOfBtPnjzB/fsZmDz5AwCAubnFc18/MXEXvvrqC3h6euHdd6fgwYP7iIvbhtTUS1i1ar1OjtzcHHz44RR06xaEoKAeOHr0EFasWIpmzVqgU6fO5X7P+sKqrgZo3sgW7/Zrg6VxF7B8+0VMDfeGqQl/NCEiIjI2SffOYvOVOCjVSgDA46JsbL4SBwBVWrC3b98RdnZ1cOjQfp1i/dCh/dBoNAgODkHz5i3QrVt3nfM6d34TEyaMxrFjhxEa2rvcr7dp0zrk5GRj9eoNcHf3AAD07BmGIUMGlDr288//DZnsry8C/fuHY968r5CQEIOxY9+FVCpF+/avIT4+Bjk52QgJ6fXC11apVFixYilatHDD0qXfQyqVAgDc3T3w+eezsWtXAsLDB2uPf/DgPv75z38jOPjpNKCwsH4IDw/Dnj07WKxT5fm0qIeRPd2xNvEK1iamYkxYa4hFIqFjERER1TinMs7gZMZvlTr3Rs6fUGlUOm1KtRKbUmPxy92kCvXVqWF7dGzoX6kcpqamCAzsju3b4/Dw4UPUq1cPAHDo0AE4O7ugdes2OserVCrk58vh7OwCKytrXLt2pULF+smTP8PLy0dbqANAnTp1EBzcEwkJMTrH/r1QLyjIh0KhhI+PH3bsiMetWzfRsqVbhd7rlSuX8fjxI22hXyIwMBjffrsYv78f/ekAACAASURBVPzys06xbmVlhe7dQ7SPJRIJWrXyxN27dyr0uvrCYr0GecO7EbLlCiT8eB12VjJEdGshdCQiIiL6m2cL9Ze1G1JwcCji42Nw5MgBREYOxc2bN/DHH9cwevRYAEBRUSE2bPgBiYm7kJn5QGf3dLlcXqHXun//Hry8fEq1N25ceoPH69fTsGrVCpw9+xvy8/N1nsvPr9jrAk+n9pT1WmKxGM7OLrh/X3ffGkfH+hA9c8HT2toGaWl/VPi19YHFeg0T1qkJsuVF2HvqT9hZyRDc3kXoSERERDVKx4b+lb6i/enPX+FxUXap9joyO7zfdsKrRqsQLy8fNGzohIMH9yEycigOHtwHANrpHwsXzkNi4i5ERAxBmzZesLKyAiDC559/olO461NeXh4mTx4HCwsrjBkzAU5OzpBKpbh27QpWrFha5g2p+iYWm5TZbqj3/DIs1msYkUiEYd3dkCtXYOvh32FrJUWHVvWFjkVEREQA+jYP1ZmzDgASsQR9m1d+mcRX0b17D2zYsBbp6bdx+PABuLu30l6BLpmXPnnyNO3xRUVFFb6qDgD16zdAevrtUu1//nlL5/G5c2eQk5ODOXPm6ayTXvYKNOWb7tugQUPta/29T41Gg/T023B1bV6ufoTCuxBrILFYhHF9W6Olsy1W776M1FuPhY5EREREeHoT6VCPQagjswPw9Ir6UI9BVb4aTIkePXoCAJYtW4j09Ns6a6uXdYU5Lm6bzhKK5dWpU2dcuJCMq1evaNseP36Mgwf36hxXsjb6369iK5XKUvPaAcDc3LxcXxw8PFqjTp262L49FkrlX1+Sjh49jMzMB3j99aq/abQieGW9hpKYmmByuDf+s/EslsWnYMbQtmhc31roWERERLVehwZtBSvOn+Xq2gwtWrjhxIkfIRaLERT0142Vr78egP37E2FpaYWmTV1x6dIFnD6dBFtb2wq/ztChI7F/fyI++GAiwsMHQyYzw86dCahfvyHk8t+1x3l5ecPa2gZz5nyO8PAoiEQi7N+fiLJmoLi7e+DAgb1YunQBPDxaw9zcAgEBb5Y6ztTUFO++OxlfffUFJk8ej+7de+DBg/uIjd2GZs2ao0+f0ivSGBNeWa/BLM0kmBbpAzOpKRbGJONh9hOhIxEREZGRKbma7ufnr10VBgCmTp2OkJBeOHhwL5YtW4SHDx9i0aJvX7ie+fPUq1cPS5Z8D1fX5tiw4QfExGxBaGgvREQM1jnO1tYOc+cuhL19PaxatQJbtmxEu3Yd8d57U0r12a/fIISE9ERi4m588cWnWLRo3nNfv1evPvj88zkoKirEt98uRmLiLgQHh2Lx4u/KXOvdmIg0Qs2WNzJZWXKo1fr9KBwcrJGZmafXPivjTqYcX288CxtLKT4Z7g8rc4nQkYhembGML6KaiOPrL/fu3UKDBqVXLCEqy8v+XsRiEeztrSrUJ6+s1wJODlaYEu6NhzmFWByTjCJlxeeaEREREVHVY7FeS7i52GF8X09cz8jFd9svorgKlj4iIiIiolfDYr0W8Xd3wFvBbkhOy8L6fVcFWy+UiIiIiMqHq8HUMt3aOuOxXIHdv9xEHWsZ+r/RTOhIRERERPQcLNZroQFvuCJbXoSdP9+EnZUMXf2chI5ERERERGVgsV4LiUQijAx1R26+AhsOXIWNpRRt3RyEjkVEREREz+Cc9VrKRCzGu/3awLWhDb7feQnXbmcLHYmIiIiInsFivRaTSU0wNdwbdW3MsCQ2BXce5gsdiYiIyOhwQQYqD0P9nQharCsUCsybNw8BAQHw9vZGZGQkTp48We7zd+3ahfDwcPj6+qJDhw546623kJKSYsDENY+1hRQfRvpAYirGwujzeJRbKHQkIiIio2FiYgqlUiF0DKoGlEoFTEz0P8Nc0GJ95syZWLduHfr27YvZs2dDLBZj7NixOHfu3EvPXbhwIWbOnImWLVti9uzZmDhxIlxcXJCZmVkFyWuWenbmmBbpg4JCFRbGJCO/UCl0JCIiIqNgZWWH7OxMKBRFvMJOZdJoNFAoipCdnQkrKzu99y/SCPSXl5KSgoiICMyaNQujRo0CABQVFSEsLAyOjo7YtGnTc889e/Yshg4diqVLlyI4OFgvebKy5FCr9ftRVLftmlNvPsKC6GQ0d7LFh1E+kJiaCB2J6Lmq2/giqk44vnQ9eZIPuTwbxcUqoaOQkTIxMYWVlR3MzS1feJxYLIK9vVWF+hZsNZh9+/ZBIpEgIiJC2yaTyRAeHo6FCxfiwYMHcHR0LPPc9evXw8vLC8HBwVCr1Xjy5AksLV/84dDLtWpaF++Etcb3Oy9h5a7LeLdfG4jFIqFjERERCcrc3PKlRRiRoQg2DSY1NRWurq6limxvb29oNBqkpqY+99yTJ0/Cy8sLCxYsgL+/P9q2bYvAwEDs3LnT0LFrvI6t62NwUEucuZqJzYeu8Sc/IiIiIgEJdmU9MzMT9evXL9Xu4PB0ve8HDx6UeV5OTg6ys7OxZ88emJiYYPr06bCzs8OmTZvw0UcfwdzcXG9TY2qrHu1dkJ1XhH1Jf8LOSoaw15sKHYmIiIioVhKsWC8sLIREIinVLpPJADydv16WgoICAEB2djaio6Ph4+MDAAgODkZwcDC+/fbbShXrFZ0/VF4ODtYG6dfQ3o3wRaFKjfgfr8OloS26d2gsdCSiUqrr+CKqDji+iIyDYMW6mZkZlMrSq46UFOklRfuzStqdnZ21hToASKVShISEYP369cjPz6/wHHbeYFra0KAWyHyUj6XR5yFSF8O7eT2hIxFpVffxRWTMOL6IDKMyN5gKNmfdwcGhzKkuJUsvPu/mUjs7O0ilUtSrV7pwrFevHjQaDeRyuX7D1lKmJmK8N8ALLo5WWL79Iq7fzRU6EhEREVGtIlix7uHhgRs3biA/X3fXzOTkZO3zZRGLxWjVqhXu379f6rl79+7BxMQEtra2+g9cS5nLTPF+pA9sLaVYFJOMe48KhI5EREREVGsIVqyHhoZCqVQiJiZG26ZQKBAfH4+2bdtqbz69e/cu0tLSSp2bkZGBn3/+Wdsml8uxd+9e+Pn5wczMrGreRC1haynFB5G+EImABdvOI0de9v0ERERERKRfgm2KBABTp07F4cOHMXLkSDRu3BgJCQm4ePEi1q1bB39/fwDA8OHDkZSUhKtXr2rPe/LkCQYOHIj79+9j1KhRsLGxQVxcHG7cuKFzbkVwzvrL3cjIxX83n0WDuhaYMbQtzGWC3fJAVOPGF5Ex4fgiMoxqNWcdAObOnYvhw4djx44d+Pe//w2VSoWVK1e+tNg2NzfH+vXrERQUhI0bN2LBggWwsrLC2rVrK1WoU/m4NrTBxAFeuJOZj2XxF6AqVgsdiYiIiKhGE/TKujHhlfXy+/lCBtbsSUXH1vUxtk9riEXc5ZSqXk0dX0TGgOOLyDAqc2Wd8xiowjp7NUS2vAhxx6/DzkqKqMCWQkciIiIiqpFYrFOl9HqtCbLlCuxPug07KxlCuGkSERERkd6xWKdKEYlEGBLUEjnyImw78gdsraR4rXUDoWMRERER1SiC3mBK1ZtYLMLYPq3h7mKHNbtTcenmI6EjEREREdUoLNbplUhMTTB5kBca2ltgWfwF3LrHG5KIiIiI9IXFOr0yCzMJpkX6wsrMFAtjkpGZ/UToSEREREQ1Aot10os61jJMi/RFcbEaC7adR26BQuhIRERERNUei3XSm0b1LDE13AeP8oqwOCYZRYpioSMRERERVWss1kmvWjjbYkJfT9y8l4cVOy5yl1MiIiKiV8BinfTOz80Bw0PckZKWhXX7roCb5BIRERFVDtdZJ4Po6uuE7Lwi7Pz5JuysZBjUpbnQkYiIiIiqHRbrZDD9AlyRLVdgz8lbsLOSIcjfWehIRERERNUKi3UyGJFIhOEhbsjNV2DzwWuwtZSinYej0LGIiIiIqg3OWSeDMhGLMb6fJ5o52WDlrsu4+udjoSMRERERVRss1sngZBITTA33gYOdGZbEXUD6A7nQkYiIiIiqBRbrVCWszCWYFukDmUSMhTHJeJRbKHQkIiIiIqPHYp2qTD1bc3wQ6YtChQrfbDsP+ROl0JGIiIiIjBqLdapSzo5WmDzQG5nZT7AkLgUKJXc5JSIiInoeFutU5Tya1MHYPp5IS8/B9zsvQa3mpklEREREZWGxToJo7+GIId1b4tzvD7HxwFXuckpERERUBq6zToLp3s4F2XIFEn+9BTtrGfp2dhU6EhEREZFRYbFOghrUpRmy5UXY/tMN2FnJ8KZPI6EjERERERkNFuskKJFIhFE9PZCbr8C6fVdgYyGFb8t6QsciIiIiMgqcs06CMzUR470BbdCkvjW+23ERaXdyhI5EREREZBRYrJNRMJOa4v0IH9hZy7AoJhkZWflCRyIiIiISHIt1Mho2llJ8EOkDE7EIC7Yl43FekdCRiIiIiATFYp2MimMdC7wf6QN5oRILo5NRUKgSOhIRERGRYFisk9Fp2sAGEwe0QUZWPpbFp0CpUgsdiYiIiEgQLNbJKLVxtcfbvVrhyp/ZWL37MtTcNImIiIhqIS7dSEarU5sGyM4vQszRNNhaSTEkqCVEIpHQsYiIiIiqDIt1MmqhHRojO0+Bg6dvo461DD07NhE6EhEREVGVYbFORk0kEiEqqAVySq6wW0rxepuGQsciIiIiqhIs1snoiUUijOndGrn5CqxNvAIbSynauNoLHYuIiIjI4HiDKVULElMxJg30RqN6lvg2/iJuZOQKHYmIiIjI4FisU7VhYWaKaZE+sDKXYHFMMh48LhA6EhEREZFBsVinasXOSoYPonyg1gALtiUjN18hdCQiIiIig2GxTtVOQ3tLTA33Rra8CAtjklGo4C6nREREVDOxWKdqqbmTLSb0b4Pb9+VYnnARqmLuckpEREQ1D4t1qrZ8W9TDiFB3XLzxCGsTr0DDXU6JiIiohuHSjVStvenTCDnyIiT8dAN21lJEdG0hdCQiIiIivWGxTtVe2OtN8ViuwN5f/4SdlQzB7VyEjkRERESkFyzWqdoTiUR4K9gNOfIibD30O2wtpejQqr7QsYiIiIheGeesU40gFoswvq8nWjjbYvXuy0i99VjoSERERESvjMU61RhSiQmmhHvDsY4FlsWn4PYDudCRiIiIiF4Ji3WqUSzNJPgg0gdmUlMsiD6PhzlPhI5EREREVGks1qnGqWtjhmmRPlAq1ViwLRnyJ0qhIxERERFViqDFukKhwLx58xAQEABvb29ERkbi5MmTLz1v6dKlcHd3L/Vf586dqyA1VQfODlaYPMgLD3MKsTg2GUXKYqEjEREREVWYoKvBzJw5EwcOHMCIESPQpEkTJCQkYOzYsdiwYQP8/Pxeev6XX34JMzMz7eO//28i98Z1ML5vayxPuIjvd1zCxIFtYCLmj0lERERUfQhWrKekpGDPnj2YNWsWRo0aBQDo378/wsLCMH/+fGzatOmlffTs2RM2NjYGTkrVmb+7I4b1cMPGA9ewYf9VjAz1gEgkEjoWERERUbkIdplx3759kEgkiIiI0LbJZDKEh4fjzJkzePDgwUv70Gg0kMvl3GaeXiiwrTPCXm+CH5MzsOPEDaHjEBEREZWbYFfWU1NT4erqCktLS512b29vaDQapKamwtHR8YV9dO3aFQUFBbC0tERISAhmzJgBOzs7Q8amamrAG82QLVdg5883YWclQ1c/J6EjEREREb2UYMV6ZmYm6tcvvcukg4MDALzwyrqNjQ2GDx8OHx8fSCQS/Prrr9i2bRsuX76MmJgYSKVSg+Wm6kkkEmFEiDty8xXYcOAqbC2l8HNzEDoWERER0QsJVqwXFhZCIpGUapfJZACAoqKi5547cuRIncehoaFo2bIlvvzyS2zfvh2RkZEVzmNvb1Xhc8rDwcHaIP1S5Xw25jXM/u5nfL/zEv414XW0drUXOhK9Ao4vIsPh+CIyDoIV62ZmZlAqS69/XVKklxTt5TVkyBDMmzcPJ0+erFSxnpUlh1qt37nvDg7WyMzM02uf9Ore698GX284gy9X/4qZb/nDqZ7ly08io8PxRWQ4HF9EhiEWiyp8gViwG0wdHBzKnOqSmZkJAC+dr/4ssViM+vXrIycnRy/5qOaysZDigyhfmJqIsTD6PB7nPf9XHCIiIiIhCVase3h44MaNG8jPz9dpT05O1j5fEUqlEhkZGahTp47eMlLN5WBnjvcjfFBQqMKC6PMoKOQup0RERGR8BCvWQ0NDoVQqERMTo21TKBSIj49H27ZttTef3r17F2lpaTrnPnr0qFR/a9asQVFREd544w3DBqcao0kDa0wa6IV7WQVYEncBShV3OSUiIiLjIticdR8fH4SGhmL+/PnIzMxE48aNkZCQgLt37+Lrr7/WHjdjxgwkJSXh6tWr2rZu3bqhV69ecHNzg1QqxalTp7B//374+/sjLCxMiLdD1VTrpnUxJqwVVu68jFW7LmNCvzYQi7lpEhERERkHwYp1AJg7dy4WLVqEHTt2ICcnB+7u7li5ciX8/f1feF6fPn1w9uxZ7Nu3D0qlEk5OTnjvvfcwfvx4mJoK+paoGnqtdQPkyhXYeuQPbDn0O4YGt+Qup0RERGQURBpu/wmAq8EQsO3I79ifdBuDujRD705NhY5DL8HxRWQ4HF9EhlGZ1WB4GZro/0V0a4EcuQJxx6/D1lKGAO+GQkciIiKiWo7FOtH/E4tEeLt3K+QWKPDD3iuwsZTCuzk3TSIiIiLhCLYaDJExMjURY+IALzg7WmL59gu4fjdX6EhERERUi7FYJ3qGucwU0yJ8YGMhxaKYZNx/VCB0JCIiIqqlWKwTlcHWSoYPo3wBAN9sO48cOXc5JSIioqrHYp3oOerXtcD7ET7ILVBgYUwynhSphI5EREREtQyLdaIXaNbIBu/190L6g3x8m3ABqmK10JGIiIioFmGxTvQS3s3tMaqnBy7ffIz/7UmFmlsTEBERURXh0o1E5RDg3RA5+UWIO34ddlYyRAa2EDoSERER1QJ6KdZVKhUOHz6MnJwcdOvWDQ4ODvrolsio9HqtCbLzFNiX9CfsrKTo0aGx0JGIiIiohqtwsT537lycOnUKcXFxAACNRoPRo0fj9OnT0Gg0sLOzQ3R0NBo3ZiFDNYtIJMKQ7i2Rk1+ErUf+gK2VDB1b1xc6FhEREdVgFZ6z/tNPP6Fdu3bax0eOHMFvv/2GMWPG4JtvvgEArFy5Un8JiYyIWCzC2D6t4eZih9W7L+PyzUdCRyIiIqIarMLF+r1799CkSRPt46NHj8LZ2RnTp09H7969MXjwYJw8eVKvIYmMicTUBFMGeaGBvQWWxV/An/fzhI5ERERENVSFi3WlUglT079mz5w6dQqvv/669rGLiwsyMzP1k47ISFmYSTAtwgcWZqZYGJ2MzOwnQkciIiKiGqjCxXqDBg1w7tw5AMDvv/+O27dvo3379trns7KyYGFhob+EREaqro0ZpkX6QlWsxoJt55FboBA6EhEREdUwFS7We/fuje3bt2P8+PEYP348rKys0KVLF+3zqampvLmUag2nepaYEu6NR3lFWByTgiJFsdCRiIiIqAapcLE+fvx4DBgwAOfPn4dIJMJ///tf2NjYAADy8vJw5MgRdOrUSe9BiYxVS2c7jO/riZv3crFix0XuckpERER6I9Jo9Lcdo1qtRn5+PszMzCCRSPTVbZXIypJDrdbvzpQODtbIzOTNh7XFsXN3sH7/VQR4NcToXh4QiURCR6rROL6IDIfji8gwxGIR7O2tKnSOXncwValUsLa21meXRNVGVz8nZMuLsPPnm7CzlmLgm82FjkRERETVXIWnwRw/fhxLly7Vadu0aRPatm0LX19ffPjhh1AqlXoLSFSd9AtwxZs+DbH7l1s4cjZd6DhERERUzVX4yvqaNWtgb2+vfZyWloavvvoKLi4ucHZ2RmJiIry8vDBq1Ch95iSqFkQiEYaHuCM3X4lNB67B1lIKf3dHoWMRERFRNVXhK+vXr19HmzZttI8TExMhk8kQGxuL1atXo1evXti+fbteQxJVJyZiMcb380SzRjb4fudlXLudLXQkIiIiqqYqXKzn5OSgTp062se//PILXnvtNVhZPZ0s36FDB6Sn8+d/qt1kEhNMjfBBPVszLIlNQXqmXOhIREREVA1VuFivU6cO7t69CwCQy+W4cOEC2rVrp31epVKhuJhrTRNZmUvwQZQPJBIxFkYn41FuodCRiIiIqJqpcLHu6+uLrVu3Yt++ffjqq69QXFyMN998U/v8rVu34OjIObpEAFDP1hzTInxQqFBhQXQy8gt58zURERGVX4WL9SlTpkCtVuP9999HfHw8+vfvjxYtWgAANBoNDh06hLZt2+o9KFF11bi+NSYN9MaDxwVYEpsChZK/PBEREVH5VGpTpOzsbJw9exbW1tZo3769tj0nJwfbt29Hx44d4eHhodeghsZNkcjQklLv4/sdl+Dbsh4mDvCCWMxNk14FxxeR4XB8ERlGZTZF0usOptUZi3WqCgdP38aWQ7+jq58Thvdw4y6nr4Dji8hwOL6IDKNKdzD9888/cfjwYdy+fRsA4OLigqCgIDRu3LiyXRLVeMHtXJAtL8LeX/9EHSsp+nR2FToSERERGbFKFeuLFi3CqlWrSq36Mm/ePIwfPx5Tp07VSziimii8S3Nk5ymQ8NMN2FnJ8IZPI6EjERERkZGqcLEeGxuL7777Dn5+fnjnnXfQsmVLAMDvv/+ONWvW4LvvvoOLiwsGDhyo97BENYFIJMLoXh7IK1Bg3b6rsLaUwrdFPaFjERERkRGq8Jz1gQMHQiKRYNOmTTA11a31VSoVhg0bBqVSifj4eL0GNTTOWaeqVqhQ4b+bzyHjYT4+GuKH5k62QkeqVji+iAyH44vIMCozZ73CSzempaWhV69epQp1ADA1NUWvXr2QlpZW0W6Jah0zqSnej/CBnZUMi2NTkJGVL3QkIiIiMjIVLtYlEgkKCgqe+3x+fj4kEskrhSKqLWwtpfggygdiEbBgWzIe5xUJHYmIiIiMSIWLdS8vL2zbtg0PHz4s9VxWVhaio6Ph4+Ojl3BEtYFjHQtMjfCB/IkSi2KSUVCoEjoSERERGYkKz1n/7bffMGrUKFhaWmLQoEHa3Uv/+OMPxMfHIz8/Hz/88APatWtnkMCGwjnrJLSL17OwODYFbi52eD/CBxLTCn+XrlU4vogMh+OLyDCqbFOkI0eO4F//+hcyMjJ02hs1aoR//OMf6Nq1a0W7FByLdTIGv1zMwOrdqejQyhHj+npCzE2Tnovji8hwOL6IDKPKNkUKDAxE165dcfHiRaSnpwN4uimSp6cnoqOj0atXLyQmJlama6Ja7fU2DZEjVyDmWBpsLWUYHNSCu5wSERHVYpXewVQsFsPb2xve3t467Y8fP8aNGzdeORhRbRXasTEey4tw8PRt1LGWIbQjdwUmIiKqrSpdrBORYYhEIgwOaokcuQLRR/+AraUUndo0EDoWERERCYDFOpEREotEeCesNfIKFPhfYiqsLSVo42ovdCwiIiKqYlxugshISUzFmDTQGw3tLfFtwkXcvJcrdCQiIiKqYizWiYyYhZkppkX6wMpMgkXRyXjw+PkbkhEREVHNU65pMGvXri13h2fPnq10GCIqrY61DB9E+eCrDWewIDoZn7zlDxtLqdCxiIiIqAqUa511Dw+PinUqEiE1NbXSoYTAddbJ2P1xJwfzt5xDo3qW+HioH8yktfuWE44vIsPh+CIyDIOts75+/fpKBSIi/WnhZIsJ/dpgaXwKlidcxJRwb5iacCYbERFRTVauYr1Dhw4GeXGFQoHFixdjx44dyM3NhYeHB6ZNm4ZOnTpVqJ+xY8fixx9/xIgRIzB79myDZCUyBr4t62FkqAd+2HsFP+y9gjG9W3HTJCIiohpM0MtyM2fOxLp169C3b1/Mnj0bYrEYY8eOxblz58rdx7Fjx3D69GkDpiQyLm/6NEL/N1zxy8V7iDt+Xeg4REREZECCFespKSnYs2cPpk+fjo8//hhRUVFYt24dGjZsiPnz55erD4VCga+//hpjxowxcFoi49Ln9abo6tsIib/ewqHTt4WOQ0RERAYiWLG+b98+SCQSREREaNtkMhnCw8Nx5swZPHjw4KV9rF+/HoWFhSzWqdYRiUR4q4c7/FrWw5ZDv+O3Ky8fL0RERFT9CFasp6amwtXVFZaWljrt3t7e0Gg0L11NJjMzE8uXL8e0adNgbm5uyKhERkksFmF8X080d7bFql2XcOXWY6EjERERkZ4JVqxnZmbC0dGxVLuDgwMAvPTK+oIFC+Dq6op+/foZJB9RdSCVmGDKIG842JljaXwKbj+QCx2JiIiI9EiwhZoLCwshkUhKtctkMgBAUVHRc89NSUnB9u3bsWHDBr2thFHRNS/Ly8HB2iD9EpVwAPDvdzvj46U/YXFsCuZNfgOOdS2EjlUlOL6IDIfji8g4CFasm5mZQalUlmovKdJLivZnaTQazJkzBz169EC7du30loebIlF1JgIwNdwbX288i0+/+xmz3vKHlXnpL8M1CccXkeFwfBEZRmU2RRJsGoyDg0OZU10yMzMBoMwpMgBw8OBBpKSkYMiQIUhPT9f+BwByuRzp6ekoLCw0XHAiI+XsYIUpg7yQmV2IxbHJKFIWCx2JiIiIXpFgxbqHhwdu3LiB/Px8nfbk5GTt82W5e/cu1Go1Ro4ciaCgIO1/ABAfH4+goCAkJSUZNjyRkXJvXAfj+rTG9Tu5+H7HJRSr1UJHIiIiolcg2DSY0NBQ/O9//0NMTAxGjRoF4Om66fHx8Wjbti3q168P4Glx/uTJEzRv3hwAEBgYCGdn51L9TZw4Ed26dUN4eDg8PT2r7H0QGZt2Ho4YGuyGTQevYcP+axgZ6s5dTomIiKopwYp1Hx8f97lV9QAAIABJREFUhIaGYv78+cjMzETjxo2RkJCAu3fv4uuvv9YeN2PGDCQlJeHq1asAgMaNG6Nx48Zl9uni4oLu3btXSX4iYxbk74xseRH2nLyFOtYy9AtwFToSERERVYJgxToAzJ07F4sWLcKOHTuQk5MDd3d3rFy5Ev7+/kLGIqoRBr7ZDNnyIuw4cQO2VlJ09XUSOhIRERFVkEij0eh3CZRqiqvBUE2kKlZjadwFXLyRhUkDveDX0kHoSHrD8UVkOBxfRIZRrVaDISLDMzUR473+bdC0gTW+23EJf6TnCB2JiIiIKoDFOlENJ5OaYGqED+pay7A4Nhl3H+a//CQiIiIyCizWiWoBGwsppkX5wsREjIXR5/E47/k7BBMREZHxYLFOVEs42pljWoQP8gtVWBh9HgWFpXcQJiIiIuPCYp2oFmnSwBoTB3ohI6sAS+MuQKniLqdERETGjMU6US3j2bQuxvRuhau3s7Fq12W9r4JERERE+sNinagWes2zASK7tcDpq5nYcvh3cAVXIiIi4yTopkhEJJzQjo2RLS/Cgd9uo461DL1eayJ0JCIiInoGi3Wi/2vvzqOjKg+/gX9nnyQzyWSSyb4QAiQhbAlVjBQVwTZaFEulWATrAlXRvgWPrYqnPefX1uJrcaviBvatUqtVFoP8LKIFaxULFTBhSUDCkoTJMlknk2VmMnPfP2ZykyEhJCSTOzP5fs7xcHLnzuQZjg/5zpPnfu8Y9uPrJ6ClzYEtn5UjKkKN2VMTpR4SERER9cKwTjSGyWUy3PuDHFjbHPh/H5UhMkKNqeNjpB4WEREReXHPOtEYp1TI8dCiqUgxReDl7Udxptoq9ZCIiIjISybwyjIAQEODbcRaMQ7UHMKO8l1otjfDoDHglsxCXJmQPyKvTeQvLTY7ntx8EHanC2uXzUS8MVzqIQ3IZNLDYmmVehhEIYnzi8g/5HIZYmJ0Q3uOn8YyZh2oOYS/lW1Fk70ZAoAmezP+VrYVB2oOST00ogFF6TR4eMkMCALwzN+/QUubQ+ohERERjXkM6yNsR/kuON2+d4Z0up0oKv+HRCMiGrwEYzh+sXgarO0OPP9eMTrsXVIPiYiIaExjWB9hTfbmfo8321uw9ovfY0PxGygq/wcO1hajtq0ObsE9yiMkGlhmUhRW3ToFlXU2vLz9CLpc/H+UiIhIKmyDGWHRGkO/gT1MGYZs40RU2cwoa/xWDOlquQpJukSk6BKRok9Csi4JSREJ0Co1oz10ItG0zFjcdWM2/vxRKf78USlWLJgMuUwm9bCIiIjGHIb1EXZLZiH+VrbVZyuMSq7CjyctFC8ydbq7UNNWhyqbGedtZlS1mnGwrgRfmPcDAGSQwRQeg2RdElJ0SWKQj1JHQsbARKPku9MS0WyzY9vnp2HQafDjuROkHhIREdGYw7A+wroD+UBtMCq5Eqn6JKTqk8RjgiCgyd6MqlYzztuqUWUzo9JahcN1JeI5OlUEUnRJSPaG9xRdEuLDTVDIFaP3BmlM+UFBOppsduzaXwGDToPvXZEq9ZCIiIjGFFY3eo1kdWO3kai+6ujqFMP7+VbPn9VtNXC6PRf+KWUKJOoSPAHeuxKfrEtEuCpsJN4CEdxuAa98cBQHT1pw3y25mDU5XuohAWC1HJE/cX4R+cflVDcyrHsFaljvj8vtQl1Hvc8qfFWrGa1Om3hOjDa6zyq8URvNbTR0WZxdLjzz92KUn2/Bwz+ejpxxRqmHxDBB5EecX0T+wbA+DMEU1i+mxd7qXYE3ewK8rRp17RYI8LyvMKUWybrEnr3w+kQkhsdDpVCN2hgpeLV1OvHUXw+hwdqJx+7IR1q8XtLxMEwQ+Q/nF5F/MKwPQyiE9f44XA6Y22p8V+Ft1XC4PDe8kcvkSAiP8wR4faK4Gq9XD+1/JBobGq2deHLzQbjdAp5YPhOxBum2WwXC/CIKVZxfRP7BsD4MoRrW++MW3KjvaOy1Cu8J8c32FvGcKHWkt0rSuxdenwRTWAzkMlbzj3Xn69vw1F8PQheuxtpl+dCHqyUZR6DOL6JQwPlF5B8M68MwlsL6xdicbeJFrJ5ayWpUt9X6dMIn6xKRrPfWSeqSkKRLhEYhTVgj6ZysbMYzf/8GqXE6/PL2PGjUo99IFGzziyiYcH4R+QfD+jAwrPfPpxO+1174jq4OAD2d8L2baNgJPzYcOmnBhu1HMHV8DH7+o6lQyEf3ty6hML+IAhXnF5F/MKwPA8P64AmCgMbOZs8Nnbzh/XyrGfWdjeI5Yie8vqdSkp3woWfv4fPY/PEJfHdaIu6+MXtUP6CF6vwiCgScX0T+cTlhnTdFoiGTyWSICYtGTFg0pplyxeMdXR04b6vx2Qv/r6p96OruhJcrkRgRf8EqfCLClOyED1Zz85LR3GrHh/vOIlqnwQ+vGS/1kIiIiEIKwzqNmDBlGCYYMjDBkCEec7ldqG23+PTBH6k/jq+q/yueE6M1IuWCvfDshA8et87JQLPNE9gNOjXm5qdIPSQiIqKQwbBOfqWQK5CkS0CSLgFXIA+AZxuN1dEqbp/p3kpTUn+8Tye8uAqvT0RiRAJUcv4vG2hkMhnuLMyCtc2Bv+4+icgIDWZmmaQeFhERUUjgnnUv7lmXnt3lgNlW490LX+3phm8buBM+RZcEnTpC4pETANidLqx/5zDO1drwyO0zMCnV4Nfvx/lF5D+cX0T+wQtMh4FhPTB5OuEb+qzC9+6EN2iifPrgk3WJ7ISXSGu7A+v+egjWNgceX5aPZJP/bq7F+UXkP5xfRP7BsD4MDOvBxeZoE7vgu/fC17TX9XTCK9RIjkj0aaNJ0iWwE34U1Dd34MnNByGXy/DE8pkwRmr98n04v4j8h/OLyD8Y1oeBYT34eTrhaz3bZ2w9N3fq6OoE4OmEjwuP9emDT9YlshPeDypqW/F//3YIRr0Wjy3LR4RWNeLfg/OLyH84v4j8g2F9GBjWQ1N3J7xnFb5nL3wDO+H9rvRsI559rxiZSZF4eMkMqFUj+/fJ+UXkP5xfRP7BsD4MDOtji9gJ32oWb+5kbqv16YRP8nbCJ4t74RPYCT9EB0pr8WrRMeRPMmHVrVMgl4/cbzA4v4j8h/OLyD94UySiQRqoE17cC99qRkn9cey7sBPeu32mexXeqDVwG81FXJkTjxabA+/881u8/elJLLthEv+uiIiIhoBhncirdyd8t55OeLPPXvgSy7FenfBh4s2cuvfCJ0TEsxPe64YrUtFks2PX/goYdBrcfPU4qYdEREQUNJgmiAYgk8kQpYlElCYSuTHZ4vHuTvjeq/BfVh/o0wl/4Sr8WO2Ev+26TLTY7Nj++WkYdGrMmZYk9ZCIiIiCAsM60WXQKNTIiEpDRlSaeKx3J3z3XviTTeU4UHNIPMegiepZhdcnIUWXiNgx0Akvl8lw9005sLY78eY/TiAyXI3pE2KlHhYREVHA4wWmXrzAlPyluxO+9yp8f53wvVfhk3UJUIdgJ3yHvQtPv3MY1fVt+OXSPGQmRV32a3F+EfkP5xeRf7ANZhgY1mk09e6E731zp/464XvXSkaq9UF/gWZLmwN/2Pw1OuwurF0+EwnG8Mt6Hc4vIv/h/CLyD4b1YWBYJ6l5OuGbPNtoeq3C9+6E16t0Pjd0CtZO+Nqmdvxh80FoVAqsXT4TBp1myK/B+UXkP5xfRP7BsD4MDOsUqHp3wnff3OminfD6JHEbTaB3wp+ptuLpvx1GXHQYHrsjH2GaoV1Cw/lF5D+cX0T+wbA+DAzrFEx6d8JX2cw43+pZjbc528RzYrVG8SLW7ps7BVon/JHTDfjTlhJMSjVg9eLpUCkHf6Et5xeR/3B+EfkHw/owMKxTsBMEAS0Oq7h9pnsrTV17ff+d8N4gL3Un/JdHqvHG/5biypw4/OyWXMgH+WGC84vIfzi/iPwj6O5g6nA48MILL6CoqAhWqxXZ2dlYs2YNCgoKBnzejh07sGXLFpSXl6OlpQVxcXGYNWsWHnroISQnJ4/S6IkCi0wmg0ETBYMmqp9O+OqevfCtZnxp3g+H2wnA0wmfGBHv0wefrE+ETjU6nfCzpyaipc2BLZ+Vw6DT4PZ5E0fl+xIREQUDScP6Y489ht27d+POO+9Eeno6tm/fjpUrV2Lz5s3Iy8u76PPKysoQHx+Pa6+9FlFRUTCbzXjvvffw2WefYceOHTCZTKP4LogCm6cTPh0ZUeniMbfghqWjwWcVvv9OeM/qu7874W+clYbmVjt2/7cSBp0GhbPSLv0kIiKiMUCybTAlJSVYvHgxHn/8cdx1110AALvdjgULFiAuLg5vv/32kF7v2LFjWLRoEX71q1/h3nvvHfJ4uA2GCGh12MQayarWapy3+XbCaxRqJOsSkewN8Sn6JCRFjEwnvFsQ8GrRMXxdVoeVN09GQW7CgOdzfhH5D+cXkX8E1TaYXbt2QaVSYfHixeIxjUaD2267Dc899xzq6uoQFxc36NdLSvLcvtxqtY74WInGCr1ah2zjRGQbe7aiOF1OVLfXiuG9ymbG17WH8e/zXwHo7oQ3XbAXPglRGv2QvrdcJsPKBTmwtTvw5/8tRWS4GrkZxhF9f0RERMFGsrBeWlqKjIwMRET47oudNm0aBEFAaWnpJcN6c3MzXC4XzGYzNmzYAACX3O9OREOjUqiQpk9Bmj5FPNbTCW9Gla0a51vNOGutwMG6YvEcvUrn0wefok9CXFjsgJ3wKqUCDy2ahqfePoSXth/BY0vzkZ4wtNBPREQUSiQL6xaLBfHx8X2Od+83r6uru+RrfP/730dzczMAwGAw4De/+Q2uuuqqkR0oEfUhk8kQE2ZETJgR001TxOPtzg5xG033n59VfoEuwQUAUMmVSIxI8Lkra7IuEWFKrfga4Vol1vx4Ov6w+Ws89943WHvndxBnCOzOeCIiIn+RLKx3dnZCpVL1Oa7ReO5kaLfbL/kaL730Etrb23HmzBns2LEDbW1tl3zOxQx1/9BgmUxcFaSxRI90xAGYLh7pcrtgttbgbHMVzjVX4WxzFY40Hse+6gPiOfERsUiPTsE4g/e/+FT89r6r8diGL/DClhI8/dAcGPSefxv+fe4A3ikpQkN7I2LCjfjJtIWYk37laL9RopDHn19EgUGysK7VauF0Ovsc7w7p3aF9IFdccQUA4Nprr8W8efNw8803Izw8HMuWLRvyeHiBKZH/hCESORGTkRMxGUju6YT3NNF49sKfbazCf6uKxU74cGUYEq6IQ8VZGR7ZXIEV82bBYq/Fuyc+gNNbO1nf3ohXD/wVVmsHrkzIl/ItEoUU/vwi8o+gusDUZDL1u9XFYrEAwJAuLgWA1NRU5Obm4sMPP7yssE5Eo6d3J/yU2BzxeE8nfM9eeHWCGVbhLJ795r/9vpbT7cT7J4sggwxapQZahQYapQZahVb8WiVXBdSdW4mIiAZLsrCenZ2NzZs3o62tzeci0+LiYvHxoers7ERHR8eIjZGIRtfFOuE/OnQcRQeLoc4sBvrJ3O1dHfjL8Xcu+rpymRwahSe4i4FeoYFWqRXDfdgFIV+j0CDM+6fWe65GoYFGoWbwJyKiUSNZWC8sLMSf//xnvP/++2LPusPhwLZt25Cfny9efGo2m9HR0YHMzEzxuY2NjTAafSvdjh49irKyMtx0002j9h6IyP/kMjkWzJwCV0cEdrWegFzT2eccgyYK/yfvZ+js6oTdZUdHlx12lx2dXXZ0ujph77KjU/y6+7FOtDisPse6++QHIoPMG/Q14p/a3sG/9wcCpQZhCq33Q0DfDwoahdovN5kiIqLQIVlYnz59OgoLC7F+/XpYLBakpaVh+/btMJvNWLdunXjeo48+igMHDuDEiRPisblz5+LGG2/EpEmTEB4ejlOnTmHr1q2IiIjAqlWrpHg7RORnt8weh4PbZ6BeeQAyRU+oFlxy5GquRnz48O5cLAgCnG5nr1DfN+R3fxjwCf7ec1vbbb0+INjh8jbgXIpaofZd1e9nG4/2ghX+nnN8PwAMVItJRETBSbKwDgBPP/00nn/+eRQVFaGlpQVZWVl4/fXXMXPmzAGft3TpUnz11Vf49NNP0dnZCZPJhMLCQqxatQqpqamjNHoiGk0ymQztNfFw1k+BMvUkZOpOCA4tuion4dC3aiz9zvBfX61QQ61QI1I9/BYMp7urn5X+zl4Bv9fXF3wgaOxs6jnHZUeXu2tQ31MlV/UE/F5bd3z38l/4WwCtb+j3/qmUS/rjgYiIvGSCIIxsBUqQYhsMUeC756k9F31s8rho5KRHIzs9GuMS9FDIQ2d7SZe764KQ399K/4UfBHw/IHQf627SuRSlXCmG/v5D/sW2+mj77PdXypXc5x9k+POLyD+Cqg2GiGioYiI1aLD2vQeDVq2Atc2Jrf86LX6dlWoQw3tKnA7yIA6LSrkSOrkSOlXEpU++BJfbdZGtPBdf6e8+p9XRCourHvYuOzpcdjhcjkF9T4VM0WfrTr+r+gOs9HcfZ7MPEY01DOtEFDQWXZuJN/9RBkdXz551tVKO5d/PQkFuAqztDpyoaEbpuSaUnmtCcXkDAEAXpkJ2Wk94TzCGj9nAp5ArEC4PR7gqfNiv5RbcsLscfbf7DGKlv72rA42dzeIxu8shduwPZGjNPr22AvX5AKBlsw8RBQVug/HiNhii4PDVsRps+1c5Gq12GCM1WHRtJgpyE/o9t9HaibKKJjG8N3pX5Q06tRjcc9KjERsVNppvgfrhFtxwuJwDtvf0d2Fv94eAjgt+QzCY4H/RZp9B7vcPU4Zusw9/fhH5x+Vsg2FY92JYJwouQ51fgiDA0twhBveyc02wtnv2b5sM2p7wnhaNKN2l76BMgau72cez0t95wcq+b8jv7HUhr3gNQK8PBB2uzkFVegIXNvt4V+8H2O8fiM0+B2oOYUf5LjTbm2HQGHBLZiHvDkw0ghjWh4FhnSi4DHd+CYIAc32bGN5PVDSj3e5pXUmKjUBOmie8Z6UZoAtTjdSwKcgIgiBe4Nv/Sn//2306LvgNQfdzugZZ6amSq/rdujNwv//wmn0O1BzC38q2+lyErJKrsDT7RwzsRCOEYX0YGNaJgstIzy+3W0BFXasY3k9WNsPhdEMGIC1eL668T0qNglbNy33o8vQO/v2v9Pu291xY+dl7u89Qm30udROvvVVfoqOr713AozUG/H722pH+qyAakxjWh4FhnSi4+Ht+dbncOFNtFbfMnDrfgi6XAIVchozESHG/+4TkSKiUvBkRjb7+mn0Gt9Lf2WcL0KWafTZc//QovSui0MawPgwM60TBZbTnl8PpwqnzLWJ4P1PdCrcgQKmQY2JKlBjeMxJDq+Odxga34Mav961Ds72lz2NcWScaOexZJyLyE7VKgcnjjJg8zggA6LB34WRlT03k9s9PYzs8He+TvB3vOSHQ8U5jg1wmx8LMG/vds35LZqGEIyMihnUiossQplFi+oRYTJ8QCwBovaDjvcTb8R6hVYqr7jljvOOdAlv3RaRsgyEKLNwG48VtMETBJdDnV1OrHWXnujveG8U7r0Z5O95z0rwd7wZ2vFPgCfT5RRSsuA2GiChAROs1KJiSgIIpCZ6O95ZOMbwfP9uE/xyrBQDERmnFVffs9GgY2PFORES9MKwTEfmZTCZDnCEMcYYwXDM9ydPx3tAuhvdDJy34d0k1ACAxJlwM71lp0ex4JyIa4xjWiYhGmUwmQ3JsBJJjIzBvZgrcbgGVdTZxv/uXR2qw59B5yACkxuvE8D4xxYAwDf/ZJiIaS7hn3Yt71omCSyjPry6XG2erW1F6rhGl55pw6rwVXS435DIZMpL04p73zOQoqFXseKeRF8rzi0hK7FkfBoZ1ouAyluaXw+lC+fkWlFZ4Vt7PmHs63ickR3pX3o0Yl6iHUsGOdxq+sTS/iEYTw/owMKwTBZexPL867F34tqqnJrKy1gYBgEbl2/GeGqeDXM6aSBq6sTy/iPyJbTBERGNAmEaJaZmxmJbp6Xi3dThxoqJJDO/v7e3peM9K62maSYphxzsRUbBhWCciCnK6MBVmZsVhZlYcAKDZ1rvj3dM2AwBREWoxuOekR8PEjnciooDHsE5EFGIMOg2uyk3AVbkJAABLc4cnvFc0ofRsE/5z3NPxHhPp2/EerWfHOxFRoGFYJyIKcSZDGEyGMMzxdrzXNLaLq+6Hv7XgiyM9He/Z3qaZ7HR2vBMRBQKGdSKiMUQmkyExJgKJMRG4Pj8FbkFAZa2n472sogn7jtZg76HzAIC0OJ24ZWZSKjveiYikwDYYL7bBEAUXzi//6HK5cbam1RPezzXh26qWno73RL0Y3iew4z2kcX4R+QerG4eBYZ0ouHB+jQ5nlwunzlvF8H6m2gqXW4BSIcOE5CgxvGckRrLjPYRwfhH5B8P6MDCsEwUXzi9peDreW8S2mYraVrHjfWJqlHjBalqcnh3vQYzzi8g/2LNORER+5el4j8G0zBgA3R3vzWLbzPt7ywEA4RolstJ6btCUFBvBjnciosvAsE5ERJfN0/FuwswsEwCgxWZHaUWTuPJ++Nt6AEBkhBrZvcK7yRDG8E5ENAgM60RENGKidBpcNTkBV032dLzXN3eI4f34uSYcKK0DAMREasT97jnpRna8ExFdBMM6ERH5TawhDHMMYZgzrafjvXvVvfhUA748UgMAiDeGi6vuWWkGRIarJR45EVFgYFgnIqJR0bvjfa63472qziaG9/8cq8Fnhz0d7ykmHSaP89ycKYsd70Q0hrENxottMETBhfMr9Ljcno737vD+bVULnF2ejvdxiXrkpHvC+4TkKGjY8e5XnF9E/sHqxmFgWCcKLpxfoc/Z5UK5t+O9tKIJZ8w9He+ZSVFieB+fxI73kcb5ReQfDOvDwLBOFFw4v8aeToen4720u+O9xtPxrlbJMSnFIIb39Hh2vA8X5xeRf7BnnYiIQpZWrcTU8TGYOt7T8d7W6el477676vufeTrewzRKZKcZxLaZZHa8E1EQY1gnIqKgFKFVIX+SCfmTvB3vbQ5xv3tZ7473cBWyvavuOenRiGPHOxEFEYZ1IiIKCVERasyaHI9Zk+MBAPUtHSg71+zdNtModrwbIzXISesJ78ZIrZTDJiIaEMM6ERGFpNioMHx3Whi+Oy0RgiCgtqlD3O9eXN6AL496O96jw8T97tlp0YiMYMc7EQUOhnUiIgp5MpkMCcZwJBjDMTcvGW5BwHlLm7hlZn9pLT77xgwASDFFiKvuWakGhGtVEo+eiMYytsF4sQ2GKLhwftFIcrndOFdjQ+m5RpR5O94dXW7IZMC4BL0Y3icmG6BRh37HO+cXkX+wunEYGNaJggvnF/mTs8uN0+YWceW93NvxrpDLkJkUiZxxRuSEcMc75xeRfzCsDwPDOlFw4fyi0WR3uPDt+Z6ayLM1rRAEQK2UY2Kqp+M9Jz0aafE6KOTBH945v4j8gz3rREREfqBRKzAlIwZTMjwd7+2dTpyo7AnvW3p1vGf1Cu9JpgjIWRNJRMPAsE5ERDRE4VoV8iaakDfR0/FubXOgrKJJbJv55pSn410frkJ2WrQY3uOi2fFOREPDsE5ERDRMkRFqXJkTjytzPB3vDS2dPuH9v2WejvdovUYM7ux4J6LBYFgnIiIaYTFRWsyemojZUz0d73W9Ot6PnG7APm/He5y34z2HHe9EdBEM60RERH4kk8kQbwxHvDEc13k73s3ejvfSc004UFqLf3k73pNNEcjxbpvJSmPHOxFJ3AbjcDjwwgsvoKioCFarFdnZ2VizZg0KCgoGfN7u3bvx0UcfoaSkBA0NDUhMTMTcuXOxatUq6PX6yxoL22CIggvnF4UKl9uNilqbGN6/rWwWO97T4/XiyvvElNHreOf8IvKPoKtufPjhh7F7927ceeedSE9Px/bt23H06FFs3rwZeXl5F33erFmzEBcXh/nz5yMpKQknTpzAu+++i3HjxmHr1q3QaDRDHgvDOlFw4fyiUOXscuNMtVUM7+XnW8SO9/FJkWJ4H58UBZXSPzWRnF9E/hFUYb2kpASLFy/G448/jrvuugsAYLfbsWDBAsTFxeHtt9++6HP379+PWbNm+Rz74IMP8Oijj2LdunVYtGjRkMfDsE4UXDi/aKywO104VdUihvezNVax431CSpRnv3t6NMYl6Ees453zi8g/gqpnfdeuXVCpVFi8eLF4TKPR4LbbbsNzzz2Huro6xMXF9fvcC4M6AMyfPx8AUF5e7p8BExERSUCjUiA3w4jcDCMAoL2zCye9He+l55qw9V+nAQBataKn432cEcnseCcKCZKF9dLSUmRkZCAiIsLn+LRp0yAIAkpLSy8a1vtTX+/ptI2Ojh7RcRIREQWScK0SMybGYsbEWACAtd2BExU94b24vAEAoAtTIbtXTWQ8O96JgpJkYd1isSA+Pr7PcZPJc4OJurq6Ib3exo0boVAo8L3vfW9ExkdERBQMIsPVuCI7Dldkexa4Gq2+He9f9+p4732Dppiovh3vXx2rwbZ/laPRaocxUoNF12aiIDdhVN8PEfmSLKx3dnZCpepbSdV9cajdbh/0a3344YfYsmUL7rvvPqSlpV3WeIa6f2iwTKbLa6chokvj/CLqy2TSIyvThIUABEFATUM7Sk5ZUPJtPUpO1eOrY56O98SYCEybGItpE2IxdUIsik9a8NauE7A7XQCABqsdb+06gUi9FtfNTJXwHRGNbZKFda1WC6fT2ed4d0gfbKPL119/jSeeeALXXXcdfvGLX1z2eHiBKVFw4fwiGhwlgPzMGORnxkAQJsFc39Px/vnh8/j4P+cAAAq5DK4Lfg7anS78Zecx5KYZJBg5UegJqgtMTSZTv1tdLBYLAAxqv3pZWRkeeOABZGVl4bnnnoNCMTr9s0RERMFIJpMh2aRDskmH+d9Jhdst4FxtK8rONeH9z/ovaGiwDv433UQ08vw2w0K7AAALTklEQVRT0DoI2dnZOHPmDNra2nyOFxcXi48PpKKiAitWrIDRaMRrr72G8PBwv42ViIgoFMnlMmQkRuLGq9IRE9n/b7QvdpyIRodkYb2wsBBOpxPvv/++eMzhcGDbtm3Iz88XLz41m8196hgtFgvuueceyGQyvPHGGzAajaM6diIiolCz6NpMqC+4yZJaKceiazMlGhERARJug5k+fToKCwuxfv16WCwWpKWlYfv27TCbzVi3bp143qOPPooDBw7gxIkT4rEVK1agsrISK1aswMGDB3Hw4EHxsbS0tAHvfkpERER9dbe+sA2GKLBIFtYB4Omnn8bzzz+PoqIitLS0ICsrC6+//jpmzpw54PPKysoAAJs2berz2A9/+EOGdSIiostQkJuAgtwEXsBNFEBkgiCMbAVKkGIbDFFw4fwi8h/OLyL/uJw2GMn2rBMRERER0cAY1omIiIiIAhTDOhERERFRgGJYJyIiIiIKUAzrREREREQBimGdiIiIiChAMawTEREREQUohnUiIiIiogAl6R1MA4lcLguq1yUizi8if+L8Ihp5lzOveAdTIiIiIqIAxW0wREREREQBimGdiIiIiChAMawTEREREQUohnUiIiIiogDFsE5EREREFKAY1omIiIiIAhTDOhERERFRgGJYJyIiIiIKUAzrREREREQBimGdiIiIiChAKaUeQCipq6vDW2+9heLiYhw9ehTt7e146623MGvWLKmHRhT0SkpKsH37duzfvx9msxkGgwF5eXlYvXo10tPTpR4eUVA7cuQIXn31VRw/fhwNDQ3Q6/XIzs7Ggw8+iPz8fKmHRxRSNm7ciPXr1yM7OxtFRUWXPJ9hfQSdOXMGGzduRHp6OrKysnD48GGph0QUMjZt2oRDhw6hsLAQWVlZsFgsePvtt3Hrrbdiy5YtyMzMlHqIREGrsrISLpcLixcvhslkQmtrKz788EMsW7YMGzduxOzZs6UeIlFIsFgseOWVVxAeHj7o58gEQRD8OKYxxWazwel0Ijo6Gp9++ikefPBBrqwTjZBDhw5hypQpUKvV4rGzZ8/i5ptvxg9+8AM89dRTEo6OKPR0dHRg/vz5mDJlCl577TWph0MUEh577DGYzWYIggCr1TqolXXuWR9BOp0O0dHRUg+DKCTl5+f7BHUAGDduHCZOnIjy8nKJRkUUusLCwmA0GmG1WqUeClFIKCkpwY4dO/D4448P6XkM60QUtARBQH19PT8kE40Qm82GxsZGnD59Gs8++yxOnjyJgoICqYdFFPQEQcDvfvc73HrrrcjJyRnSc7lnnYiC1o4dO1BbW4s1a9ZIPRSikLB27Vp8/PHHAACVSoXbb78d999/v8SjIgp+H3zwAU6dOoUNGzYM+bkM60QUlMrLy/Hb3/4WM2fOxMKFC6UeDlFIePDBB7FkyRLU1NSgqKgIDocDTqezzxY0Iho8m82GZ555Bj/72c8QFxc35OdzGwwRBR2LxYL77rsPUVFReOGFFyCX858yopGQlZWF2bNn40c/+hHeeOMNHDt2bMj7a4nI1yuvvAKVSoW77777sp7Pn3BEFFRaW1uxcuVKtLa2YtOmTTCZTFIPiSgkqVQqzJs3D7t370ZnZ6fUwyEKSnV1dXjzzTexdOlS1NfXo6qqClVVVbDb7XA6naiqqkJLS8uAr8FtMEQUNOx2O+6//36cPXsWf/nLXzB+/Hiph0QU0jo7OyEIAtra2qDVaqUeDlHQaWhogNPpxPr167F+/fo+j8+bNw8rV67EI488ctHXYFgnoqDgcrmwevVqfPPNN3j55ZcxY8YMqYdEFDIaGxthNBp9jtlsNnz88cdITExETEyMRCMjCm4pKSn9XlT6/PPPo729HWvXrsW4ceMGfA2G9RH28ssvA4DY+1xUVISDBw8iMjISy5Ytk3JoREHtqaeewp49ezB37lw0Nzf73EgiIiIC8+fPl3B0RMFt9erV0Gg0yMvLg8lkQnV1NbZt24aamho8++yzUg+PKGjp9fp+fz69+eabUCgUg/rZxTuYjrCsrKx+jycnJ2PPnj2jPBqi0LF8+XIcOHCg38c4v4iGZ8uWLSgqKsKpU6dgtVqh1+sxY8YM3HPPPbjyyiulHh5RyFm+fPmg72DKsE5EREREFKDYBkNEREREFKAY1omIiIiIAhTDOhERERFRgGJYJyIiIiIKUAzrREREREQBimGdiIiIiChAMawTEREREQUohnUiIpLM8uXLcf3110s9DCKigKWUegBERDSy9u/fjzvvvPOijysUChw/fnwUR0RERJeLYZ2IKEQtWLAA11xzTZ/jcjl/qUpEFCwY1omIQtTkyZOxcOFCqYdBRETDwOUVIqIxqqqqCllZWXjxxRexc+dO3HzzzZg6dSquu+46vPjii+jq6urznLKyMjz44IOYNWsWpk6diptuugkbN26Ey+Xqc67FYsHvf/97zJs3D1OmTEFBQQHuvvtufPnll33Ora2txcMPP4wrrrgC06dPx7333oszZ8745X0TEQUTrqwTEYWojo4ONDY29jmuVquh0+nEr/fs2YPKykrccccdiI2NxZ49e/DSSy/BbDZj3bp14nlHjhzB8uXLoVQqxXP37t2L9evXo6ysDM8884x4blVVFX7yk5+goaEBCxcuxJQpU9DR0YHi4mLs27cPs2fPFs9tb2/HsmXLMH36dKxZswZVVVV46623sGrVKuzcuRMKhcJPf0NERIGPYZ2IKES9+OKLePHFF/scv+666/Daa6+JX5eVlWHLli3Izc0FACxbtgwPPfQQtm3bhiVLlmDGjBkAgCeffBIOhwPvvvsusrOzxXNXr16NnTt34rbbbkNBQQEA4H/+539QV1eHTZs2Yc6cOT7f3+12+3zd1NSEe++9FytXrhSPGY1G/PGPf8S+ffv6PJ+IaCxhWCciClFLlixBYWFhn+NGo9Hn66uvvloM6gAgk8mwYsUKfPrpp/jkk08wY8YMNDQ04PDhw7jhhhvEoN597gMPPIBdu3bhk08+QUFBAZqbm/Hvf/8bc+bM6TdoX3iBq1wu79Nec9VVVwEAzp07x7BORGMawzoRUYhKT0/H1VdffcnzMjMz+xybMGECAKCyshKAZ1tL7+O9jR8/HnK5XDy3oqICgiBg8uTJgxpnXFwcNBqNzzGDwQAAaG5uHtRrEBGFKl5gSkREkhpoT7ogCKM4EiKiwMOwTkQ0xpWXl/c5durUKQBAamoqACAlJcXneG+nT5+G2+0Wz01LS4NMJkNpaam/hkxENGYwrBMRjXH79u3DsWPHxK8FQcCmTZsAAPPnzwcAxMTEIC8vD3v37sXJkyd9zn399dcBADfccAMAzxaWa665Bp9//jn27dvX5/txtZyIaPC4Z52IKEQdP34cRUVF/T7WHcIBIDs7Gz/96U9xxx13wGQy4Z///Cf27duHhQsXIi8vTzzviSeewPLly3HHHXdg6dKlMJlM2Lt3L7744gssWLBAbIIBgF//+tc4fvw4Vq5ciVtvvRW5ubmw2+0oLi5GcnIyfvnLX/rvjRMRhRCGdSKiELVz507s3Lmz38d2794t7hW//vrrkZGRgddeew1nzpxBTEwMVq1ahVWrVvk8Z+rUqXj33Xfxpz/9Ce+88w7a29uRmpqKRx55BPfcc4/Puampqdi6dSs2bNiAzz//HEVFRYiMjER2djaWLFninzdMRBSCZAJ/H0lENCZVVVVh3rx5eOihh/Dzn/9c6uEQEVE/uGediIiIiChAMawTEREREQUohnUiIiIiogDFPetERERERAGKK+tERERERAGKYZ2IiIiIKEAxrBMRERERBSiGdSIiIiKiAMWwTkREREQUoBjWiYiIiIgC1P8Hqwuc2RBUZYMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5kEOv-hkiN4",
        "colab_type": "text"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyRZK8T-kn8r",
        "colab_type": "text"
      },
      "source": [
        "### 5.1. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGo5HVGrktZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT_-aTa6lHNQ",
        "colab_type": "text"
      },
      "source": [
        "## 5.2. Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9gGzvrglKve",
        "colab_type": "text"
      },
      "source": [
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxhCS5Y6lQKN",
        "colab_type": "code",
        "outputId": "dbfc7641-8782-4729-98fd-1fb7a2d765a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,000 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WurJqPopcBz",
        "colab_type": "code",
        "outputId": "a2c6f66c-da52-4b7f-ef38-725c9107bd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate accuracy for test dataset\n",
        "total_accuracy = 0\n",
        "for batch_num in range(len(predictions)): \n",
        "  total_accuracy += flat_accuracy(predictions[batch_num], true_labels[batch_num])\n",
        "\n",
        "total_accuracy = total_accuracy/len(predictions)*100\n",
        "print('Accuracy on test dataset:', total_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test dataset: 92.7734375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkLp5IdFZBMm",
        "colab_type": "text"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrtddlMYY_mI",
        "colab_type": "code",
        "outputId": "ea1f876b-fbc7-49c9-a703-775b5133ec46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = 'drive/My Drive/DSI/model/'\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to drive/My Drive/DSI/model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('drive/My Drive/DSI/model/vocab.txt',\n",
              " 'drive/My Drive/DSI/model/special_tokens_map.json',\n",
              " 'drive/My Drive/DSI/model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH_lppdxaW8x",
        "colab_type": "text"
      },
      "source": [
        "# Load Model back from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24VDQATnZCfH",
        "colab_type": "code",
        "outputId": "0dac05fc-f791-46cd-96dd-d633f98b4cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}